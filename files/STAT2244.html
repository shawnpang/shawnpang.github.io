<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>The Practice of Statistics in the Life Sciences</title>
</head>
<body>
<div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_SVG_Hidden"></div><svg><defs id="MathJax_SVG_glyphs"><path id="MJMATHI-72" stroke-width="1" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMATHI-69" stroke-width="1" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJMATHI-73" stroke-width="1" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJMATHI-6B" stroke-width="1" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJMAIN-28" stroke-width="1" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJMATHI-41" stroke-width="1" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path><path id="MJMAIN-29" stroke-width="1" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJMAIN-3D" stroke-width="1" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJMATHI-70" stroke-width="1" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path id="MJMATHI-6F" stroke-width="1" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJMATHI-64" stroke-width="1" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path id="MJMAIN-2F" stroke-width="1" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path id="MJMAIN-31" stroke-width="1" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJMAIN-2212" stroke-width="1" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJMATHI-50" stroke-width="1" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path id="MJMATHI-61" stroke-width="1" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJMATHI-6E" stroke-width="1" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJMATHI-42" stroke-width="1" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path><path id="MJMAIN-7C" stroke-width="1" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path id="MJMAIN-2B" stroke-width="1" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJMAIN-5C" stroke-width="1" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z"></path><path id="MJMAIN-74" stroke-width="1" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJMAIN-65" stroke-width="1" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJMAIN-41" stroke-width="1" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"></path><path id="MJMAIN-78" stroke-width="1" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path id="MJMAIN-20" stroke-width="1"></path><path id="MJMAIN-61" stroke-width="1" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJMAIN-6E" stroke-width="1" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJMAIN-64" stroke-width="1" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path><path id="MJMAIN-42" stroke-width="1" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path id="MJMATHI-7A" stroke-width="1" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path><path id="MJMATHI-78" stroke-width="1" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJMATHI-3BC" stroke-width="1" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path><path id="MJMATHI-3C3" stroke-width="1" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path><path id="MJSZ3-28" stroke-width="1" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path><path id="MJSZ3-29" stroke-width="1" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path><path id="MJMAIN-21" stroke-width="1" d="M78 661Q78 682 96 699T138 716T180 700T199 661Q199 654 179 432T158 206Q156 198 139 198Q121 198 119 206Q118 209 98 431T78 661ZM79 61Q79 89 97 105T141 121Q164 119 181 104T198 61Q198 31 181 16T139 1Q114 1 97 16T79 61Z"></path><path id="MJMATHI-58" stroke-width="1" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path><path id="MJMAIN-62" stroke-width="1" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path id="MJMAIN-69" stroke-width="1" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJMAIN-221A" stroke-width="1" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path><path id="MJSZ2-221A" stroke-width="1" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path><path id="MJSZ1-221A" stroke-width="1" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path><path id="MJMAIN-2265" stroke-width="1" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path id="MJMATHI-65" stroke-width="1" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJMATHI-75" stroke-width="1" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMAIN-AF" stroke-width="1" d="M69 544V590H430V544H69Z"></path><path id="MJMAIN-5E" stroke-width="1" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path id="MJMAIN-73" stroke-width="1" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJMAIN-71" stroke-width="1" d="M33 218Q33 308 95 374T236 441H246Q330 441 381 372L387 364Q388 364 404 403L420 442H457V156Q457 -132 458 -134Q462 -142 470 -145Q491 -148 519 -148H535V-194H527L504 -193Q480 -192 453 -192T415 -191Q312 -191 303 -194H295V-148H311Q339 -148 360 -145Q369 -141 371 -135T373 -106V-41V49Q313 -11 236 -11Q154 -11 94 53T33 218ZM376 300Q346 389 278 401Q275 401 269 401T261 402Q211 400 171 350T131 214Q131 137 165 82T253 27Q296 27 328 54T376 118V300Z"></path><path id="MJMAIN-66" stroke-width="1" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJMAIN-70" stroke-width="1" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z"></path><path id="MJMAIN-72" stroke-width="1" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJMAIN-6F" stroke-width="1" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJMAIN-6D" stroke-width="1" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJMAIN-6C" stroke-width="1" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJMAIN-79" stroke-width="1" d="M69 -66Q91 -66 104 -80T118 -116Q118 -134 109 -145T91 -160Q84 -163 97 -166Q104 -168 111 -168Q131 -168 148 -159T175 -138T197 -106T213 -75T225 -43L242 0L170 183Q150 233 125 297Q101 358 96 368T80 381Q79 382 78 382Q66 385 34 385H19V431H26L46 430Q65 430 88 429T122 428Q129 428 142 428T171 429T200 430T224 430L233 431H241V385H232Q183 385 185 366L286 112Q286 113 332 227L376 341V350Q376 365 366 373T348 383T334 385H331V431H337H344Q351 431 361 431T382 430T405 429T422 429Q477 429 503 431H508V385H497Q441 380 422 345Q420 343 378 235T289 9T227 -131Q180 -204 113 -204Q69 -204 44 -177T19 -116Q19 -89 35 -78T69 -66Z"></path><path id="MJMATHI-4E" stroke-width="1" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJMAIN-63" stroke-width="1" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path id="MJMAIN-75" stroke-width="1" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path id="MJMAIN-5B" stroke-width="1" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path id="MJMAIN-5D" stroke-width="1" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path id="MJMAIN-7A" stroke-width="1" d="M42 263Q44 270 48 345T53 423V431H393Q399 425 399 415Q399 403 398 402L381 378Q364 355 331 309T265 220L134 41L182 40H206Q254 40 283 46T331 77Q352 105 359 185L361 201Q361 202 381 202H401V196Q401 195 393 103T384 6V0H209L34 1L31 3Q28 8 28 17Q28 30 29 31T160 210T294 394H236Q169 393 152 388Q127 382 113 367Q89 344 82 264V255H42V263Z"></path><path id="MJMAIN-68" stroke-width="1" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJMATHI-74" stroke-width="1" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path id="MJMATHI-6D" stroke-width="1" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMAIN-B1" stroke-width="1" d="M56 320T56 333T70 353H369V502Q369 651 371 655Q376 666 388 666Q402 666 405 654T409 596V500V353H707Q722 345 722 333Q722 320 707 313H409V40H707Q722 32 722 20T707 0H70Q56 7 56 20T70 40H369V313H70Q56 320 56 333Z"></path><path id="MJMATHI-67" stroke-width="1" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path id="MJMATHI-66" stroke-width="1" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path id="MJMAIN-67" stroke-width="1" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path id="MJMAIN-2217" stroke-width="1" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path><path id="MJMATHI-48" stroke-width="1" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJMAIN-30" stroke-width="1" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJMAIN-3A" stroke-width="1" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path id="MJMAIN-32" stroke-width="1" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJSZ1-28" stroke-width="1" d="M152 251Q152 646 388 850H416Q422 844 422 841Q422 837 403 816T357 753T302 649T255 482T236 250Q236 124 255 19T301 -147T356 -251T403 -315T422 -340Q422 -343 416 -349H388Q359 -325 332 -296T271 -213T212 -97T170 56T152 251Z"></path></defs></svg></div><div id="wmd-preview" class="wmd-preview"><div class="md-section-divider"></div><div class="md-section-divider"></div><h1 data-anchor-id="6v5k" id="the-practice-of-statistics-in-the-life-sciences">The Practice of Statistics in the Life Sciences</h1><div class="md-section-divider"></div><h2 data-anchor-id="31aj" id="math"><code>math</code></h2><p data-anchor-id="q0iq"><div class="toc"><div class="toc">
<ul>
<li><a href="#the-practice-of-statistics-in-the-life-sciences">The Practice of Statistics in the Life Sciences</a><ul>
<li><a href="#math">math</a></li>
<li><a href="#i-exploring-data">I Exploring Data</a><ul>
<li><a href="#1-picturing-distributions-with-graphs">1. Picturing Distributions with Graphs</a></li>
<li><a href="#2-describing-distributions-with-numbers">2. Describing Distributions with Numbers</a></li>
<li><a href="#3-scatterplots-and-correlation">3. Scatterplots and Correlation</a></li>
<li><a href="#4-regression">4. Regression</a></li>
<li><a href="#5-two-way-tables">5. Two-Way Tables</a></li>
<li><a href="#6-exploring-data-part-i-review">6. Exploring Data: Part I Review</a></li>
</ul>
</li>
<li><a href="#ii-from-exploration-to-inference">II From Exploration to Inference</a><ul>
<li><a href="#7-samples-and-observational-studies">7. Samples and Observational Studies</a><ul>
<li><a href="#71-observation-versus-experiment">7.1 Observation versus Experiment</a></li>
<li><a href="#72-sampling">7.2 Sampling</a></li>
<li><a href="#73-sampling-designs">7.3 Sampling Designs</a></li>
<li><a href="#74-sample-surveys">7.4 Sample Surveys</a></li>
<li><a href="#75-coherts-and-case-control-studies">7.5 Coherts and Case-Control Studies</a></li>
</ul>
</li>
<li><a href="#8-designing-experiments">8. Designing Experiments</a><ul>
<li><a href="#81-designing-experiments">8.1 Designing Experiments</a></li>
<li><a href="#82-randomized-comparative-experiments">8.2 Randomized Comparative Experiments</a></li>
<li><a href="#83-common-experimental-designs">8.3 Common Experimental Designs</a></li>
<li><a href="#84-cautions-about-experimentation">8.4 Cautions about experimentation</a></li>
<li><a href="#85-ethics-in-experimentation">8.5 Ethics in Experimentation</a></li>
</ul>
</li>
<li><a href="#9-introducing-probability">9. Introducing Probability</a><ul>
<li><a href="#91-the-idea-of-probability">9.1 The Idea of Probability</a></li>
<li><a href="#92-probability-models">9.2 Probability Models</a></li>
<li><a href="#93-probability-rules">9.3 Probability Rules</a></li>
<li><a href="#94-discrete-probability-models">9.4 Discrete Probability Models</a></li>
<li><a href="#95-continuous-probability-models">9.5 Continuous Probability Models</a></li>
<li><a href="#96-random-variables">9.6 Random Variables</a></li>
<li><a href="#97-personal-probability">9.7 Personal Probability</a></li>
<li><a href="#98-risk-and-odds">9.8 Risk and Odds</a></li>
</ul>
</li>
<li><a href="#10-general-rules-of-probability">10. General Rules of Probability</a><ul>
<li><a href="#101-relationships-among-several-events">10.1 Relationships among Several Events</a></li>
<li><a href="#102-conditional-probability">10.2 Conditional Probability</a></li>
<li><a href="#103-general-probability-rules">10.3 General Probability Rules</a></li>
<li><a href="#104-tree-diagrams">10.4 Tree Diagrams</a></li>
<li><a href="#105-bayes-theorem">10.5 Baye's Theorem</a></li>
</ul>
</li>
<li><a href="#11-the-normal-distributions">11. The Normal Distributions</a><ul>
<li><a href="#111-normal-distributions">11.1 Normal Distributions</a></li>
<li><a href="#112-the-68-95-997-rule">11.2 The 68-95-99.7 Rule</a></li>
<li><a href="#113-the-standard-normal-distribution">11.3 The Standard Normal Distribution</a></li>
<li><a href="#114-finding-normal-probabilities">11.4 Finding Normal Probabilities</a></li>
<li><a href="#115-using-the-standard-normal-table">11.5 Using the Standard Normal Table</a></li>
<li><a href="#116-finding-a-value-given-a-probability-or-a-proportion">11.6 Finding a Value, Given a Probability or a Proportion</a></li>
<li><a href="#117-normal-quantile-plots">11.7 Normal Quantile Plots</a></li>
</ul>
</li>
<li><a href="#12-discrete-probability-distributions">12. Discrete Probability Distributions</a><ul>
<li><a href="#121-the-binomial-setting-and-binomial-distributions">12.1 The Binomial Setting and Binomial Distributions</a></li>
<li><a href="#122-binomial-distributions-in-statistical-sampling">12.2 Binomial Distributions in Statistical Sampling</a></li>
<li><a href="#123-binomial-probabilities">12.3 Binomial Probabilities</a></li>
<li><a href="#124-binomial-mean-and-standard-deviation">12.4 Binomial Mean and Standard Deviation</a></li>
<li><a href="#125-the-normal-approximation-to-binomial-distributions">12.5 The Normal Approximation to Binomial Distributions</a></li>
<li><a href="#126-the-poisson-distributions">12.6 The Poisson Distributions</a></li>
</ul>
</li>
<li><a href="#13-sampling-distributions">13. Sampling Distributions</a><ul>
<li><a href="#131-parameters-and-statistics">13.1 Parameters and Statistics</a></li>
<li><a href="#132-statistical-estimation-and-sampling-distributions">13.2 Statistical Estimation and Sampling Distributions</a></li>
<li><a href="#133-the-sampling-distribution-of-barx">13.3 The Sampling Distribution of \bar{x}</a></li>
<li><a href="#134-the-central-limit-theorem">13.4 The Central Limit Theorem</a></li>
<li><a href="#135-the-sampling-distribution-of-hatp">13.5 The Sampling Distribution of \hat{p}</a></li>
<li><a href="#136-the-law-of-large-numbers">13.6 The Law of Large Numbers</a></li>
</ul>
</li>
<li><a href="#14-introduction-to-inference">14. Introduction to Inference</a><ul>
<li><a href="#141-the-reasoning-of-statistical-estimation">14.1 The Reasoning of Statistical Estimation</a></li>
<li><a href="#142-margin-of-error-and-confidence-level">14.2 Margin of Error and Confidence Level</a></li>
<li><a href="#143-confidence-intervals-for-the-mean-mu">14.3 Confidence Intervals for the Mean \mu</a></li>
<li><a href="#144-the-reasoning-of-tests-of-significance">14.4 The Reasoning of Tests of Significance</a></li>
<li><a href="#145-stating-hypotheses">14.5 Stating Hypotheses</a></li>
<li><a href="#146-p-value-and-statistical-significance">14.6 P-Value and Statistical Significance</a></li>
<li><a href="#147-test-for-a-population-mean">14.7 Test for a Population Mean</a></li>
<li><a href="#148-tests-from-confidence-interval">14.8 Tests from Confidence Interval</a></li>
</ul>
</li>
<li><a href="#15-inference-in-practice">15. Inference in Practice</a><ul>
<li><a href="#151-conditions-for-inference-in-practice">15.1 Conditions for Inference in Practice</a></li>
<li><a href="#152-how-confidence-intervals-behave">15.2 How Confidence Intervals Behave</a></li>
<li><a href="#153-how-significance-tests-behave">15.3 How Significance Tests Behave</a></li>
<li><a href="#154-sample-size-for-confidence-intervals">15.4 Sample Size for Confidence Intervals</a></li>
<li><a href="#155-sample-size-for-test-of-significance-the-power-of-statistical-test">15.5 Sample Size for Test of Significance: The Power of Statistical Test</a></li>
</ul>
</li>
<li><a href="#16-from-exploration-to-inference">16. From Exploration to Inference</a></li>
</ul>
</li>
<li><a href="#iii-statistical-inference">III Statistical Inference</a><ul>
<li><a href="#17-inference-about-a-population-mean">17 Inference about a Population Mean</a></li>
<li><a href="#18-comparing-two-means">18. Comparing Two Means</a></li>
<li><a href="#19-inference-about-a-population-proportion">19. Inference about a Population Proportion</a></li>
<li><a href="#20-comparing-two-proportions">20. comparing Two Proportions</a></li>
<li><a href="#21-the-chi-square-test-for-goodness-of-fit">21. The Chi-Square Test for Goodness of Fit</a></li>
<li><a href="#22-the-chi-square-test-for-two-way-tables">22. The Chi-Square Test for Two-Way Tables</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</p><hr><div class="md-section-divider"></div><h2 data-anchor-id="zjvg" id="i-exploring-data">I Exploring Data</h2><div class="md-section-divider"></div><h3 data-anchor-id="1kjv" id="1-picturing-distributions-with-graphs">1. Picturing Distributions with Graphs</h3><div class="md-section-divider"></div><h3 data-anchor-id="j93l" id="2-describing-distributions-with-numbers">2. Describing Distributions with Numbers</h3><div class="md-section-divider"></div><h3 data-anchor-id="khmo" id="3-scatterplots-and-correlation">3. Scatterplots and Correlation</h3><div class="md-section-divider"></div><h3 data-anchor-id="14t3" id="4-regression">4. Regression</h3><div class="md-section-divider"></div><h3 data-anchor-id="ad6g" id="5-two-way-tables">5. Two-Way Tables</h3><div class="md-section-divider"></div><h3 data-anchor-id="t13z" id="6-exploring-data-part-i-review">6. Exploring Data: Part I Review</h3><div class="md-section-divider"></div><h2 data-anchor-id="k9m2" id="ii-from-exploration-to-inference">II From Exploration to Inference</h2><hr><div class="md-section-divider"></div><h3 data-anchor-id="1oqx" id="7-samples-and-observational-studies">7. Samples and Observational Studies</h3><div class="md-section-divider"></div><h4 data-anchor-id="7q98" id="71-observation-versus-experiment">7.1 Observation versus Experiment</h4><ul data-anchor-id="dixh">
<li>An <strong>observational study</strong> observes individuals and measures variables of <br>
interest but does not attempt to influence the responses. The purpose of an <br>
observational study is to describe and compare existing groups or situations.</li>
<li>An <strong>experiment</strong>, on the other hand, deliberately imposes some treatment on <br>
individuals in order to observe their responses. The purpose of an experiment <br>
is to study whether the treatment causes a change in the response. <br>
<strong>*Confounding</strong>: Two variables (explanatory variables or lurking variables) are <strong>confounded</strong> <br>
when their effects on a response variable cannot be distinguished from each <br>
other. <br>
<ul><li>Observational studies of the effect of one variable on another often fail to demonstrate causality because the explanatory variable is confounded with lurking variables.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="6mbm" id="72-sampling">7.2 Sampling</h4><ul data-anchor-id="jq7u">
<li><strong>Population</strong>: The <strong>population</strong> in a statistical study is the entire group of individuals (not necessarily people) about which we want information.</li>
<li><strong>Sample</strong> A <strong>sample</strong> is the part of the population from which we actually collect information. We use a sample to draw conclusions about the entire population.</li>
<li><strong>Sampling design</strong>: A <strong>sampling design</strong> describes exactly how to choose a sample from the population</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="un4z" id="73-sampling-designs">7.3 Sampling Designs</h4><ul data-anchor-id="ln83">
<li><strong>Inference</strong>: The process of drawing conclusions about a population on the basis of sample data is called statistical inference because we infer information about the population from inference what we know about the sample.</li>
<li>Poor Sampling Designs <br>
<ul><li><strong>Convenience sample</strong>: The easiest—but not the best—sampling design just chooses individuals close at hand. This is called a convenience sample, and it convenience sample <br>
often produces unrepresentative data.</li>
<li><strong>voluntary response sample</strong>: The voluntary response sample, lets individuals choose whether to participate or not. The problem is that people who take the trouble to respond to an open invitation are usually not representative of any clearly defined population.</li>
<li><strong>Bias</strong>: The design of a statistical study is <strong>biased</strong> if it systematically favors certain outcomes.</li></ul></li>
<li>Simple Random Samples <br>
<ul><li><strong>Simple Random Sample</strong>: A simple random sample (SRS) of size n consists of n individuals from the population chosen in such a way that every set of n individuals has an equal chance to be the sample actually selected.</li></ul></li>
<li>Other Probability Sampling Designs <br>
<ul><li><strong>stratified samples</strong>: The approach to sample important groups within the population separately and then to combine these samples is the approach of <strong>stratified samples</strong>.</li>
<li><strong>Multistage Samples</strong>: Multistage sampling can be a complex form of cluster sampling because it is a type of sampling which involves dividing the population into groups (or clusters). Then, one or more clusters are chosen at random and everyone within the chosen cluster is sampled.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="461l" id="74-sample-surveys">7.4 Sample Surveys</h4><ul data-anchor-id="0f7i">
<li>Use of Sample Surveys <br>
<ul><li><strong>Sample</strong>: A sample survey is an observational study that relies on a random sample drawn from the entire population at one point in time. </li>
<li><strong>Cross-Sectional Studies</strong>: In medical research and social science, a cross-sectional study (also known as a cross-sectional analysis, transverse study, prevalence study) is a type of observational study that analyzes data from a population, or a representative subset, at a specific point in time—that is, cross-sectional data. <br>
<ul><li>sample surveys are sometimes called cross-sectional studies;</li></ul></li>
<li>Sample surveys may collect lots of data for each individual sampled. In addition <br>
to the main questions of interest, personal information about the respondents is often recorded, such as gender, age, and sociodemographics.  <br>
<ul><li>This enables the comparison of results between subgroups of individuals at the data analysis stage.</li></ul></li></ul></li>
<li>Problems <br>
<ul><li><strong>Undercoverage</strong>: Undercoverage occurs when some groups in the population are left out of the process of choosing the sample.</li>
<li><strong>nonresponse</strong>: Nonresponse occurs when a selected individual cannot be contacted or refuses to cooperate. <br>
<ul><li>Do not confuse nonresponse in a probability sample and opt-in polls that use a voluntary response sample. Nothing can be done with voluntary response samples to make the respondents more representative of the intended target population.</li></ul></li>
<li><strong>response bias</strong>:  the behavior of the respondent or of the interviewer can cause response bias in sample results. </li>
<li><strong>wording effect</strong>: The wording of questions can strongly influence the answers given to a sample survey. <br>
<ul><li>Confusing or leading questions can introduce strong bias, and even minor changes in wording can change a survey’s outcome.</li></ul></li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="tfxe" id="75-coherts-and-case-control-studies">7.5 Coherts and Case-Control Studies</h4><ul data-anchor-id="axwk">
<li>Case Control Study:  <br>
<ul><li>A random sample of individuals with a condition (the <strong>cases</strong>) is compared with a random sample of individuals without the condition (the <strong>controls</strong>).</li>
<li>In a case-control observational study, case-subjects are selected based on a defined outcome, and a control group of subjects is selected separately to serve as a baseline with which the case group is compared.</li>
<li><strong>Retrospective</strong>: Looking back into the past is called a retrospective approach. </li>
<li>Case-control studies are efficient ways to approach rare outcomes and often give fast results, within the usual limitations of observational studies.</li></ul></li>
<li>Cohort Study: <br>
<ul><li><strong>Prospective</strong>: Prospective stydies record at regular intervals all sorts of new relevant information about the study participants.</li>
<li>After some time, individuals who have developed a condition are then compared with the remaining, unaffected individuals.</li>
<li><strong>Longitudinal</strong>: Observational studies that monitor a sample of individuals repeatedly over time are sometimes called longitudinal studies. </li>
<li>**Cohort Study*: *In a cohort study, subjects sharing a common demographic characteristic are enrolled and observed at regular intervals over an extended period of time.</li>
<li>Cohort studies accumulate enormous amounts of detailed information and can examine the compounded effect of various factors over time. However, they also take a long time to complete and lose subjects over time, creating a potential confounding <br>
effect. T</li></ul></li>
</ul><hr><div class="md-section-divider"></div><h3 data-anchor-id="aqnm" id="8-designing-experiments">8. Designing Experiments</h3><div class="md-section-divider"></div><h4 data-anchor-id="tjpi" id="81-designing-experiments">8.1 Designing Experiments</h4><ul data-anchor-id="e6on">
<li>Definitions <br>
<ul><li><strong>Subject</strong>: The <strong>individuals</strong> (or units) studied in an experiment are often called <strong>subjects</strong> when they are people, and <strong>experimental units</strong> otherwise.</li>
<li><strong>Factor</strong>: The explanatory variables in an experiment are often called <strong>factors</strong>.</li>
<li><strong>Treatment</strong>: A treatment is any specific experimental condition applied to the subjects. If an experiment has more than one factor, a treatment is a combination of specific values of each factor.</li></ul></li>
<li>Advantages of Experiments over Observational Studies <br>
<ul><li>In an experiment, we can study the effects of the specific treatments in which we are interested. </li>
<li>By assigning subjects to treatments, we can avoid confounding.</li>
<li>we can study the combined effects of several factors simultaneously. The interaction of several factors can produce effects that could not be predicted from looking at the effect of each factor alone.</li>
<li>Experiments are the preferred method for examining the effect of one variable on another. By imposing the specific treatment of interest and controlling other influences, we can pin down cause and effect. </li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="qw6o" id="82-randomized-comparative-experiments">8.2 Randomized Comparative Experiments</h4><ul data-anchor-id="qb8y">
<li><p>Definitions</p>

<ul><li><strong>Experimental Group</strong>: An experimental group is a group of individuals receiving a treatment whose effect we seek to understand.</li>
<li><strong>Control Group</strong>: A control group serves as a baseline with which the experimental group is compared.</li>
<li><strong>Placebo</strong>: A placebo is a control treatment that is fake (for example, taking a sugar <br>
pill) but otherwise indistinguishable from the treatment in the experimental group. <br>
<ul><li>The placebo effect is documented in human experimentation only, in contexts <br>
as diverse as the study of asthma or high blood pressure. </li>
<li>The effect is particularly strong when the response variable is pain.  </li></ul></li>
<li><strong>Statistical Significance</strong>: An observed effect so large that it would rarely occur by chance is called statistically significant. <br>
<ul><li>We know that in general a strong observed association does not imply causation. </li>
<li>A statistically significant association in data from a well-designed experiment does imply causation.</li></ul></li></ul></li>
<li><p>Randomization</p>

<ul><li><strong>Randomized Comparitive Experiment</strong>: An experiment that uses both comparison of two or more treatments and chance assignment of subjects to treatments is a randomized comparative experiment.</li>
<li>Randomized comparative experiments are designed to give good evidence that differences in the treatments actually cause the differences we see in the response. Reasons below: <br>
<ul><li>Random assignment of subjects forms groups that should be similar in all respects before the treatments are applied. The random assignment also allows us to use probability laws to conduct statistical inference on the data collected.</li>
<li>Comparative design ensures that influences other than the experimental treatments operate equally on all groups.</li>
<li>Therefore, differences in average response must be due either to the treatments or to the play of chance in the random assignment of subjects to the treatments.</li></ul></li></ul></li>
<li>Principles of Experimental Design <br>
<ul><li><strong>Control</strong>: Control the effects of lurking variables on the response, most simply by comparing two or more treatments.</li>
<li><strong>Randomize</strong>: use impersonal chance to assign subjects to treatments.</li>
<li><strong>Repetition</strong>: Use enough subjects in each group to reduce chance variation in the <br>
results.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="0xyo" id="83-common-experimental-designs">8.3 Common Experimental Designs</h4><ul data-anchor-id="wvuc">
<li>Completely Randomized Designs <br>
<ul><li>In a <strong>completely randomized</strong> experimental design, all the individuals are allocated at random among all the treatments. <br>
<ul><li>Note that it is not necessary for a completely randomized design to assign the same number of individuals to each treatment. It might be advantageous or more practical to assign a larger number of individuals to one particular treatment.</li>
<li>Completely randomized designs can compare any number of treatments. </li>
<li>They can also have more than one factor.</li></ul></li>
<li>Completely randomized designs are the simplest statistical designs for experiments. They illustrate clearly the principles of comparison, randomization, and adequate number of subjects. <br>
<ul><li>However, experiments sometimes need additional sophistication—for example, to deal with substantial individual-to-individual variability or potentially confounding variables.</li></ul></li></ul></li>
<li><p>Block Design</p>

<ul><li><ul><li><strong>Block</strong>: A block is a group of individuals that are known before the experiment to be similar in some way that is expected to affect the response to the treatments.</li></ul></li>
<li><strong>Block Design</strong>: In a block design, the random assignment of individuals to treatments is carried out separately within each block. <br>
<ul><li>Blocks are another form of control. They control the effects of some outside variables by bringing those variables into the experiment to form the blocks.</li>
<li>A wise experimenter will form blocks based on the most important unavoidable sources of variability among the subjects or experimental units.</li>
<li>Randomization will then average out the effects of the remaining variation and allow an unbiased comparison of the treatments.</li></ul></li></ul></li>
<li><p>Matched Pair Designs</p>

<ul><li>A <strong>matched pairs design</strong> compares exactly two treatments, either by using a series of individuals that are closely matched two by two or by using each individual twice. <br>
<ul><li>A matched pairs design uses a form of blocking to compare just two treatments. </li>
<li>Matched pairs designs require that the assignment of the two treatments within each “pair” be <strong>randomized</strong> to avoid a systematic bias.</li></ul></li>
<li>Fields that study mainly human subjects, such as psychology and sociology, often reserve the term “matched pairs” for actual pairs of similar but different individuals. <br>
<ul><li><strong>Repeated Measure</strong>: When the same individuals are used for both treatments, the term repeated measures is often used instead.</li></ul></li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="938f" id="84-cautions-about-experimentation">8.4 Cautions about experimentation</h4><ul data-anchor-id="kb8f">
<li>The logic of a randomized comparative experiment depends on our ability to treat all the subjects identically in every way except for the actual treatments being compared. <br>
<ul><li><strong>Double Blind</strong>: In a double-blind experiment, neither the subjects nor the people who interact with them know which treatment each subject is receiving. <br>
<ul><li>Double-blinding is obviously necessary whenever the investigator evaluates the experimental outcome.</li>
<li>Double-blinding controls the influence of these human interactions by preventing potential bias.</li>
<li>Blinding is a challenge if subjects are able to differentiate the treatments.</li></ul></li>
<li><strong>Double Dummy</strong>: Double dummy is a technique for retaining the blind when administering supplies in a clinical trial, when the two treatments cannot be made identical. Supplies are prepared for Treatment A (active and indistinguishable placebo) and for Treatment B (active and indistinguishable placebo).</li>
<li><strong>Single Blind</strong>: A type of clinical trial in which only the investigators know which treatment (or other intervention) the participants are receiving.</li></ul></li>
<li>Many—perhaps most—experiments have some weaknesses in detail. The environment of an experiment can influence the outcomes in unexpected ways.  <br>
<ul><li><strong>Replication</strong>: Although experiments are the gold standard for evidence of cause and effect, really convincing evidence usually requires that the study be replicated successfully by its investigators as well as by independent investigators in different locations. </li>
<li><strong>Lack of Realism</strong>: The most serious potential weakness of experiments is lack of realism. The subjects or treatments or setting of an experiment may not realistically duplicate the conditions we really want to study.  <br>
<ul><li>Lack of realism can limit our ability to apply the conclusions of an experiment to the settings of greatest interest</li>
<li>Statistical analysis of an experiment cannot tell us how far the results will generalize.</li></ul></li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="vu0a" id="85-ethics-in-experimentation">8.5 Ethics in Experimentation</h4><ul data-anchor-id="k2bf">
<li>In the end, ethics must be the overarching principle guiding experimentation.  <br>
<ul><li>No matter what experiments could be done and what we might gain from them, we need to ask ourselves if the end justifies the means and be open to a continuing debate.</li></ul></li>
<li>Principles <br>
<ul><li>The organization that carries out the study must have an institutional review board that reviews all planned studies in advance in order to protect the subjects from possible harm.</li>
<li>All individuals who are subjects in a study must give their informed consent in writing before data are collected.</li>
<li>All individual data must be kept confidential. </li></ul></li>
</ul><hr><div class="md-section-divider"></div><h3 data-anchor-id="yybe" id="9-introducing-probability">9. Introducing Probability</h3><div class="md-section-divider"></div><h4 data-anchor-id="0som" id="91-the-idea-of-probability">9.1 The Idea of Probability</h4><ul data-anchor-id="9tg7">
<li>Chance behavior is unpredictable in the short run but has a regular and predictable pattern in the long run. <br>
<ul><li>The idea of probability is empirical -  it is based on observation rather than theorizing.</li></ul></li>
<li>Randomness and Probability <br>
<ul><li><strong>Random</strong>: We call a phenomenon random if individual outcomes are uncertain but there is nonetheless a regular distribution of outcomes in a large number of repetitions.</li>
<li><strong>Probability</strong>: The probability of any outcome of a random phenomenon is the proportion of times the outcome would occur in a very long series of repetitions. <br>
<ul><li>Probability describes frequentist only what happens in the <strong>long run</strong>. This is called a frequentist approach to defining probabilities, because we rely on the relative frequency (proportion) of one particular outcome among very many observations of the random phenomenon.</li></ul></li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="pgs8" id="92-probability-models">9.2 Probability Models</h4><ul data-anchor-id="jess">
<li><strong>Sample Space</strong>: The sample space S of a random phenomenon is the set of all possible outcomes.</li>
<li><strong>Event</strong>: An event is an outcome or a set of outcomes of a random phenomenon. That is, an event is a subset of the sample space.</li>
<li><strong>Probability Model</strong>: A probability model is a mathematical description of a random phenomenon consisting of two parts: a sample space S and a way of assigning probabilities <br>
to events.</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="znje" id="93-probability-rules">9.3 Probability Rules</h4><ul data-anchor-id="ehmt">
<li>Any probability is a number between 0 and 1, inclusively.</li>
<li>All possible outcomes together must have probability 1.</li>
<li>If two events have no outcomes in common, the probability that one or the other occurs is the sum of their individual probabilities.</li>
<li>The probability that an event does not occur is 1 minus the probability that the event does occur.</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="m93w" id="94-discrete-probability-models">9.4 Discrete Probability Models</h4><ul data-anchor-id="7u37">
<li><strong>Discrete</strong> A probability model with a sample space made up of a list of individual outcomes is called discrete. <br>
<ul><li>To assign probabilities in a discrete model, list the probabilities of all the individual outcomes. </li>
<li>These probabilities must be numbers between 0 and 1 and must have sum 1. </li>
<li>The probability of any event is the sum of the probabilities of the outcomes making up the event.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="hwxj" id="95-continuous-probability-models">9.5 Continuous Probability Models</h4><ul data-anchor-id="a3hg">
<li>Definition <br>
<ul><li><strong>Density Curve</strong> A density curve is a curve that 1) is always on or above the horizontal axis, and 2) has area excatly 1 underneath it.</li>
<li>A density curve describes the overall pattern of a distribution. <br>
<ul><li>The area under the curve and above any range of values on the horizontal axis is the proportion of all observations that fall in that range.</li></ul></li>
<li><strong>Continuous Probability Model</strong>: A continuous probability model assigns probabilities as areas under a density curve. The area under the curve and above any range of values on the horizontal axis is the probability of an outcome in that range.</li></ul></li>
<li>Property <br>
<ul><li>No set of real data is exactly described by a density curve. The curve is a model, an idealized description that is easy to use and accurate enough for practical use.</li>
<li>The median is the point with half the observations on either side. So the median of a density curve is the equal-areas point.</li>
<li>The mean is the point at which the curve would balance if made of solid material of varying weight.</li>
<li>The probability model for a continuous random variable assigns probabilities to intervals of outcomes rather than to individual outcomes. <br>
<ul><li>all continuous probability models assign probability 0 to any individual outcome. Only intervals of values have positive (non-zero) probabilities. </li></ul></li>
<li>We write the mean of a density curve as µ and the standard deviation of a density curve <br>
as σ to distinguish them from the mean x and standard deviation s of actual sample data.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="vbbt" id="96-random-variables">9.6 Random Variables</h4><ul data-anchor-id="h80d">
<li><strong>Random Variable</strong>: A random variable is a variable whose value is a numerical outcome of a random phenomenon.</li>
<li><strong>Probability Distribution</strong> The probability distribution of a random variable X tells us what values X can take and how to assign probabilities to those values.</li>
<li><strong>Discrete</strong>: Random variables that have a countable (typically finite) list of possible outcomes are called <strong>discrete</strong>.</li>
<li><strong>Continuous</strong>: Random vairbales that can take on any value in an interval, with probabilities given as areas under a density curve, are called <strong>continuous</strong>.</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="24n2" id="97-personal-probability">9.7 Personal Probability</h4><ul data-anchor-id="v6gd">
<li><strong>Personal Probability</strong>: a personal probability of an outcome is a number between 0 and 1 that expresses an individual's judgement of how likely the outcome is.</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="hmh2" id="98-risk-and-odds">9.8 Risk and Odds</h4><ul data-anchor-id="m7ta">
<li><strong>Risk</strong>: the risk of an undersiable outcome of a random phenomenon is the probability of that undesirable outcome.<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-25-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -771.0903951652987 5155.055555555555 1042.1807903305973" style="width: 12.023ex; height: 2.428ex; vertical-align: -0.694ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-72"></use><use xlink:href="#MJMATHI-69" x="451" y="0"></use><use xlink:href="#MJMATHI-73" x="797" y="0"></use><use xlink:href="#MJMATHI-6B" x="1266" y="0"></use><use xlink:href="#MJMAIN-28" x="1788" y="0"></use><use xlink:href="#MJMATHI-41" x="2177" y="0"></use><use xlink:href="#MJMAIN-29" x="2928" y="0"></use><use xlink:href="#MJMAIN-3D" x="3595" y="0"></use><use xlink:href="#MJMATHI-70" x="4651" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-25">risk(A) = p</script></li>
<li><strong>Odds</strong>: the odds of any outcome of a random phenomenon is the ratio of the probability of that outcome over the probability of that outcome not occuring. <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-26-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -771.0903951652987 8875.5 1042.1807903305973" style="width: 20.578ex; height: 2.428ex; vertical-align: -0.694ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-6F"></use><use xlink:href="#MJMATHI-64" x="485" y="0"></use><use xlink:href="#MJMATHI-64" x="1009" y="0"></use><use xlink:href="#MJMATHI-73" x="1532" y="0"></use><use xlink:href="#MJMAIN-28" x="2002" y="0"></use><use xlink:href="#MJMATHI-41" x="2391" y="0"></use><use xlink:href="#MJMAIN-29" x="3142" y="0"></use><use xlink:href="#MJMAIN-3D" x="3809" y="0"></use><use xlink:href="#MJMATHI-70" x="4865" y="0"></use><use xlink:href="#MJMAIN-2F" x="5369" y="0"></use><use xlink:href="#MJMAIN-28" x="5869" y="0"></use><use xlink:href="#MJMAIN-31" x="6259" y="0"></use><use xlink:href="#MJMAIN-2212" x="6981" y="0"></use><use xlink:href="#MJMATHI-70" x="7982" y="0"></use><use xlink:href="#MJMAIN-29" x="8486" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-26">odds(A) = p/(1-p)</script></li>
</ul><hr><div class="md-section-divider"></div><h3 data-anchor-id="b0gx" id="10-general-rules-of-probability">10. General Rules of Probability</h3><div class="md-section-divider"></div><h4 data-anchor-id="rq3n" id="101-relationships-among-several-events">10.1 Relationships among Several Events</h4><ul data-anchor-id="q1ig">
<li><strong>Venn Diagram</strong>: A Venn diagram (also called primary diagram, set diagram or logic diagram) is a diagram that shows all possible logical relations between a finite collection of different sets. <br>
<ul><li><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Venn_diagram_gr_la_ru.svg/440px-Venn_diagram_gr_la_ru.svg.png" alt="Venn Diagram"></li></ul></li>
<li><p><strong>Independence</strong>: Independence means that the outcome of the first event cannot influence the outcome of the second event.</p>

<blockquote class="white-blockquote">
  <ul><li>Multiplication Rule for Independent Events <br>
  If A and B are <strong>independent</strong>, <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-48-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -768.5355472252029 10599.055555555555 1037.0710944504058" style="width: 24.636ex; height: 2.384ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><use xlink:href="#MJMATHI-41" x="1141" y="0"></use><use xlink:href="#MJMATHI-61" x="1891" y="0"></use><use xlink:href="#MJMATHI-6E" x="2421" y="0"></use><use xlink:href="#MJMATHI-64" x="3021" y="0"></use><use xlink:href="#MJMATHI-42" x="3545" y="0"></use><use xlink:href="#MJMAIN-29" x="4304" y="0"></use><use xlink:href="#MJMAIN-3D" x="4971" y="0"></use><use xlink:href="#MJMATHI-50" x="6028" y="0"></use><use xlink:href="#MJMAIN-28" x="6779" y="0"></use><use xlink:href="#MJMATHI-41" x="7169" y="0"></use><use xlink:href="#MJMAIN-29" x="7919" y="0"></use><use xlink:href="#MJMATHI-50" x="8309" y="0"></use><use xlink:href="#MJMAIN-28" x="9060" y="0"></use><use xlink:href="#MJMATHI-42" x="9450" y="0"></use><use xlink:href="#MJMAIN-29" x="10209" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-48">P(A and B) = P(A) P(B)</script> Conversely, if this condition is not satisfied, then events A and B are <strong>dependent</strong>.</li></ul>
</blockquote>

<ul><li>The multiplication rule also extends to collections of more than two events, provided that all are independent.</li>
<li>Do not assume that two events are independent unless you are told that they are or unless the events have no logical connection</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="9f85" id="102-conditional-probability">10.2 Conditional Probability</h4><blockquote data-anchor-id="yypw" class="white-blockquote">
  <p>When P (A)&gt;0, the <strong>conditional probability</strong> of B, given A, is <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-81-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1486.5279674196338 9727.555555555555 2473.0559348392676" style="width: 22.543ex; height: 5.78ex; vertical-align: -2.428ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><use xlink:href="#MJMATHI-42" x="1141" y="0"></use><use xlink:href="#MJMAIN-7C" x="1900" y="0"></use><use xlink:href="#MJMATHI-41" x="2179" y="0"></use><use xlink:href="#MJMAIN-29" x="2929" y="0"></use><use xlink:href="#MJMAIN-3D" x="3596" y="0"></use><g transform="translate(4773,0)"><rect stroke="none" width="4834" height="60" x="0" y="220"></rect><g transform="translate(60,715)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><g transform="translate(1141,0)"><use xlink:href="#MJMAIN-41"></use><use xlink:href="#MJMAIN-20" x="750" y="0"></use><use xlink:href="#MJMAIN-61" x="1001" y="0"></use><use xlink:href="#MJMAIN-6E" x="1501" y="0"></use><use xlink:href="#MJMAIN-64" x="2058" y="0"></use><use xlink:href="#MJMAIN-20" x="2614" y="0"></use><use xlink:href="#MJMAIN-42" x="2865" y="0"></use></g></g><g transform="translate(1276,-716)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><use xlink:href="#MJMATHI-41" x="1141" y="0"></use><use xlink:href="#MJMAIN-29" x="1891" y="0"></use></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-81">P(B|A) = \frac{P(\text{A and B}}{P(A)}</script> </p>
</blockquote><div class="md-section-divider"></div><h4 data-anchor-id="ddhw" id="103-general-probability-rules">10.3 General Probability Rules</h4><ul data-anchor-id="9ejd">
<li>General Addition Rule <br>


<blockquote class="white-blockquote">
  <ul>
  <li>For any two events A and B, <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-190-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -768.5355472252029 17432.444444444445 1037.0710944504058" style="width: 40.53ex; height: 2.384ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><use xlink:href="#MJMATHI-41" x="1141" y="0"></use><use xlink:href="#MJMATHI-6F" x="1891" y="0"></use><use xlink:href="#MJMATHI-72" x="2377" y="0"></use><use xlink:href="#MJMATHI-42" x="2828" y="0"></use><use xlink:href="#MJMAIN-29" x="3588" y="0"></use><use xlink:href="#MJMAIN-3D" x="4255" y="0"></use><use xlink:href="#MJMATHI-50" x="5311" y="0"></use><use xlink:href="#MJMAIN-28" x="6063" y="0"></use><use xlink:href="#MJMATHI-41" x="6452" y="0"></use><use xlink:href="#MJMAIN-29" x="7203" y="0"></use><use xlink:href="#MJMAIN-2B" x="7814" y="0"></use><use xlink:href="#MJMATHI-50" x="8815" y="0"></use><use xlink:href="#MJMAIN-28" x="9567" y="0"></use><use xlink:href="#MJMATHI-42" x="9956" y="0"></use><use xlink:href="#MJMAIN-29" x="10716" y="0"></use><use xlink:href="#MJMAIN-2212" x="11327" y="0"></use><use xlink:href="#MJMATHI-50" x="12328" y="0"></use><use xlink:href="#MJMAIN-28" x="13079" y="0"></use><g transform="translate(13469,0)"><use xlink:href="#MJMAIN-41"></use><use xlink:href="#MJMAIN-20" x="750" y="0"></use><use xlink:href="#MJMAIN-61" x="1001" y="0"></use><use xlink:href="#MJMAIN-6E" x="1501" y="0"></use><use xlink:href="#MJMAIN-64" x="2058" y="0"></use><use xlink:href="#MJMAIN-20" x="2614" y="0"></use><use xlink:href="#MJMAIN-42" x="2865" y="0"></use></g><use xlink:href="#MJMAIN-29" x="17042" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-190">P(A or B) = P(A) + P(B) - P(\text{A and B})</script> </li>
  <li><p>General Multiplication Rule</p></li>
  </ul>
</blockquote>

<blockquote class="white-blockquote">
  <ul><li>The probability that both of two events A and B happen together can be found by <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-191-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -768.5355472252029 12038.055555555555 1037.0710944504058" style="width: 27.947ex; height: 2.384ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><g transform="translate(1141,0)"><use xlink:href="#MJMAIN-41"></use><use xlink:href="#MJMAIN-20" x="750" y="0"></use><use xlink:href="#MJMAIN-61" x="1001" y="0"></use><use xlink:href="#MJMAIN-6E" x="1501" y="0"></use><use xlink:href="#MJMAIN-64" x="2058" y="0"></use><use xlink:href="#MJMAIN-20" x="2614" y="0"></use><use xlink:href="#MJMAIN-42" x="2865" y="0"></use></g><use xlink:href="#MJMAIN-29" x="4714" y="0"></use><use xlink:href="#MJMAIN-3D" x="5381" y="0"></use><use xlink:href="#MJMATHI-50" x="6438" y="0"></use><use xlink:href="#MJMAIN-28" x="7189" y="0"></use><use xlink:href="#MJMATHI-41" x="7579" y="0"></use><use xlink:href="#MJMAIN-29" x="8329" y="0"></use><use xlink:href="#MJMATHI-50" x="8719" y="0"></use><use xlink:href="#MJMAIN-28" x="9470" y="0"></use><use xlink:href="#MJMATHI-42" x="9860" y="0"></use><use xlink:href="#MJMAIN-7C" x="10619" y="0"></use><use xlink:href="#MJMATHI-41" x="10898" y="0"></use><use xlink:href="#MJMAIN-29" x="11648" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-191">P(\text{A and B}) = P(A) P(B|A)</script> </li></ul>
</blockquote></li>
<li><p>Independent Events</p>

<blockquote class="white-blockquote">
  <ul><li>Two events A and B that both have positive probability are <strong>independent</strong> if <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-192-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -768.5355472252029 6943.055555555555 1037.0710944504058" style="width: 16.159ex; height: 2.384ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><use xlink:href="#MJMATHI-42" x="1141" y="0"></use><use xlink:href="#MJMAIN-7C" x="1900" y="0"></use><use xlink:href="#MJMATHI-41" x="2179" y="0"></use><use xlink:href="#MJMAIN-29" x="2929" y="0"></use><use xlink:href="#MJMAIN-3D" x="3596" y="0"></use><use xlink:href="#MJMATHI-50" x="4653" y="0"></use><use xlink:href="#MJMAIN-28" x="5404" y="0"></use><use xlink:href="#MJMATHI-42" x="5794" y="0"></use><use xlink:href="#MJMAIN-29" x="6553" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-192">P(B|A) = P(B)</script> Because of the multiplication rule, this also implies that <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-193-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -768.5355472252029 11009.055555555555 1037.0710944504058" style="width: 25.563ex; height: 2.384ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><g transform="translate(1141,0)"><use xlink:href="#MJMAIN-41"></use><use xlink:href="#MJMAIN-20" x="750" y="0"></use><use xlink:href="#MJMAIN-61" x="1001" y="0"></use><use xlink:href="#MJMAIN-6E" x="1501" y="0"></use><use xlink:href="#MJMAIN-64" x="2058" y="0"></use><use xlink:href="#MJMAIN-20" x="2614" y="0"></use><use xlink:href="#MJMAIN-42" x="2865" y="0"></use></g><use xlink:href="#MJMAIN-29" x="4714" y="0"></use><use xlink:href="#MJMAIN-3D" x="5381" y="0"></use><use xlink:href="#MJMATHI-50" x="6438" y="0"></use><use xlink:href="#MJMAIN-28" x="7189" y="0"></use><use xlink:href="#MJMATHI-41" x="7579" y="0"></use><use xlink:href="#MJMAIN-29" x="8329" y="0"></use><use xlink:href="#MJMATHI-50" x="8719" y="0"></use><use xlink:href="#MJMAIN-28" x="9470" y="0"></use><use xlink:href="#MJMATHI-42" x="9860" y="0"></use><use xlink:href="#MJMAIN-29" x="10619" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-193">P(\text{A and B}) = P(A)P(B)</script> </li></ul>
</blockquote></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="wn06" id="104-tree-diagrams">10.4 Tree Diagrams</h4><ul data-anchor-id="l0jg">
<li><strong>Tree Diagrams</strong>: In probability theory, a tree diagram may be used to represent a probability space.Tree diagrams may represent a series of independent events (such as a set of coin flips) or conditional probabilities (such as drawing cards from a deck, without replacing the cards)</li>
<li><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/Probability_tree_diagram.svg/440px-Probability_tree_diagram.svg.png" alt="Tree Diagram" title=""></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="mjqz" id="105-bayes-theorem">10.5 Baye's Theorem</h4><ul data-anchor-id="78v7">
<li><strong>Baye's Theorem</strong>: In probability theory and statistics, Bayes' theorem (alternatively Bayes' law or Bayes' rule) describes the probability of an event, based on prior knowledge of conditions that might be related to the event. </li>
<li><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b1078eae6dea894bd826f0b598ff41130ee09c19" alt="Baye's Theorem" title=""></li>
</ul><hr><div class="md-section-divider"></div><h3 data-anchor-id="p0ql" id="11-the-normal-distributions">11. The Normal Distributions</h3><div class="md-section-divider"></div><h4 data-anchor-id="9ztf" id="111-normal-distributions">11.1 Normal Distributions</h4><ul data-anchor-id="s0pw">
<li>Definitions <br>
<ul><li><strong>Normal Curve</strong>: Normal curves are the density curves that are symmetric, single-peaked, and bell-shaped, and they describe Normal distributions.</li>
<li><strong>Normal Distribution</strong>: A <strong>Normal distribution</strong> is described by a Normal density curve. </li></ul></li>
<li>Properties of the Curve <br>
<ul><li>the exact density curve for a particular Normal distribution is described by giving its mean µ and its standard deviation σ.</li>
<li>The mean is located at the center of the symmetric curve and is the same as the median.</li>
<li>The points at which this change of curvature takes place are located at distance σ on either side of the mean µ.</li></ul></li>
<li>Importance of Normal distributions <br>
<ul><li>Normal distributions are good descriptions for some distributions of real data.</li>
<li>Normal distributions are good approximations to the results of many kinds of chance outcomes.</li>
<li>many statistical inference procedures based on Normal distributions work well for other, roughly symmetric distributions.</li></ul></li>
<li>Students and professionals often make the error of assuming that their variable is Normally distributed without first verifying this assumption by plotting the data</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="g63o" id="112-the-68-95-997-rule">11.2 The 68-95-99.7 Rule</h4><ul data-anchor-id="c9vl">
<li>The Rule <br>
<ul><li>Approximately 68% of the observations fall within n σ of the mean µ.</li>
<li>Approximately 95% of the observations fall within 2σ of µ.</li>
<li>Approximately 99.7% of the observations fall within 3σ of µ.</li></ul></li>
<li>We abbreviate the Normal distribution with  mean µ and standard deviation σ as N(µ, σ).</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="rfgf" id="113-the-standard-normal-distribution">11.3 The Standard Normal Distribution</h4><ul data-anchor-id="mohk">
<li>all Normal distributions are the same if we measure in units of size σ about the mean µ as center.  <br>
<ul><li>Changing to these units is called standardizing.</li>
<li>To standardize a value, subtract the mean of the distribution and then divide by the standard deviation. <br>


<blockquote class="white-blockquote">
  <ul>
  <li>Standardizing and z-Scores <br>
  If x is an observation from a distribution that has mean µ and standard deviation σ, the standardized value of x is <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-268-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1160.103096894077 4561.5 1875.58964411928" style="width: 10.596ex; height: 4.371ex; vertical-align: -1.722ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-7A"></use><use xlink:href="#MJMAIN-3D" x="746" y="0"></use><g transform="translate(1922,0)"><rect stroke="none" width="2518" height="60" x="0" y="220"></rect><g transform="translate(60,699)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-2212" x="794" y="0"></use><use xlink:href="#MJMATHI-3BC" x="1795" y="0"></use></g><use xlink:href="#MJMATHI-3C3" x="973" y="-686"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-268">z = \frac{x-\mu}{\sigma}</script> A standardized value is often called a <strong>z-score</strong>. </li>
  <li>A z-score tells us how many standard deviations the original observation falls away from the mean, and in which direction.</li></ul></blockquote></li>
  <li>The <strong>standard Normal distribution</strong> is the Normal distribution N(0,1) with mean 0 and standard deviation 1. <br>
  <ul><li>If a variable x has any Normal distribution N(µ, σ) with mean µ and standard deviation σ, then the standardized variable <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-269-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1160.103096894077 4561.5 1875.58964411928" style="width: 10.596ex; height: 4.371ex; vertical-align: -1.722ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-7A"></use><use xlink:href="#MJMAIN-3D" x="746" y="0"></use><g transform="translate(1922,0)"><rect stroke="none" width="2518" height="60" x="0" y="220"></rect><g transform="translate(60,699)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-2212" x="794" y="0"></use><use xlink:href="#MJMATHI-3BC" x="1795" y="0"></use></g><use xlink:href="#MJMATHI-3C3" x="973" y="-686"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-269">z = \frac{x - \mu}{\sigma}</script> has the standard Normal distribution.</li></ul></li>
  <li>standardizing a variable x by subtracting the mean and dividing by the standard deviation does not automatically make the resulting z-score Normal.  <br>
  <ul><li>The resulting z-score will follow the standard Normal distribution N(0, 1) only if the original x variable had a Normal distribution N(µ, σ).</li></ul></li>
  </ul> <br>
  <div class="md-section-divider"></div></li>
  </ul><h4 data-anchor-id="410j" id="114-finding-normal-probabilities">11.4 Finding Normal Probabilities</h4><ul data-anchor-id="i5x1">
<li><strong>Cumulative Probability</strong> The cumulative probability for a value x in a distribution is the proportion of observations in the distribution that lie at or below x.</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="9lk3" id="115-using-the-standard-normal-table">11.5 Using the Standard Normal Table</h4><p data-anchor-id="efht"><img src="http://www.growingknowing.com/Images/NormalTable1.png" alt="Standard Normal Table"> <br>
* Finding Normal Probabilities with Table B <br>
    * State the problem in terms of the observed variable x. Draw a picture that shows the proportion you want in terms of cumulative proportions. <br>
    * Standardize x to restate the problem in terms of a standard Normal variable z. <br>
    * Use Table B and the fact that the total area under the curve is 1 to find the required area under the standard Normal curve.</p><div class="md-section-divider"></div><h4 data-anchor-id="pjkk" id="116-finding-a-value-given-a-probability-or-a-proportion">11.6 Finding a Value, Given a Probability or a Proportion</h4><ul data-anchor-id="08hq">
<li>Find the given proportion in the body of the table and then read the corresponding z from the left column and top row.  There are again three steps: <br>
<ul><li>State the problem and draw a picture</li>
<li>Use the table</li>
<li>Unstandardize to transform z back to the original x scale.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="xlqb" id="117-normal-quantile-plots">11.7 Normal Quantile Plots</h4><ul data-anchor-id="scco">
<li>The most useful tool for assessing Normality is another graph, the Normal quantile plot Normal quantile plot. Process of doing it: <br>
<ul><li>Arrange the observed data values from smallest to largest. Record what percentile of the data each value occupies. For example, the smallest observation in a set of 20 is at the 5% point, the second smallest is at the 10% point, and so on. </li>
<li>Do Normal distribution calculations to find the z-scores at these same percentiles. For example, z = −1.645 is the 5% point of the standard Normal distribution, and z = −1.282 is the 10% point.</li>
<li>Plot each data point x against the corresponding z. If the data distribution is close to standard Normal, the plotted points will lie close to the 45-degree line x = z. If the data distribution is close to any Normal distribution, the plotted points will lie close to some straight line.</li></ul></li>
<li>If the points on a Normal quantile plot lie close to a straight line, the plot indicates that the data are Normal.  <br>
<ul><li>Systematic deviations from a straight line indicate a non-Normal distribution. </li>
<li>Outliers appear as points that are far away from the overall pattern of the plot.</li></ul></li>
</ul><hr><div class="md-section-divider"></div><h3 data-anchor-id="hjx5" id="12-discrete-probability-distributions">12. Discrete Probability Distributions</h3><div class="md-section-divider"></div><h4 data-anchor-id="80c5" id="121-the-binomial-setting-and-binomial-distributions">12.1 The Binomial Setting and Binomial Distributions</h4><ul data-anchor-id="etbp">
<li>The Binomial Setting <br>
<ul><li>There are a fixed number n of observations.</li>
<li>The n observations are all <strong>independent</strong>.</li>
<li>Each observation falls into one of just two categories, which for convenience we call "success" and "failure".</li>
<li>The probability of a success, call it p, is the same for each observation.</li></ul></li>
<li>The Binomial Distribution <br>
<ul><li>The count X of successes in the binomial setting has the <strong>binomial distribution</strong> with parameters n and p. The parameter n is the number of observations, and p is the probability of a success on any one observation. The possible values of X are the whole numbers from 0 to n. </li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="28xm" id="122-binomial-distributions-in-statistical-sampling">12.2 Binomial Distributions in Statistical Sampling</h4><ul data-anchor-id="o6rf">
<li>Sampling Distribution of a Count <br>
<ul><li>Choose an SRS of size n from a population with proportion p of successes. </li>
<li>When the population is much larger than the sample, the count X of successes in the sample has approximately the binomial distribution with parameters n and p.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="waz5" id="123-binomial-probabilities">12.3 Binomial Probabilities</h4><ul data-anchor-id="1ebt">
<li>Binomial Coefficient <br>
<ul><li>The number of ways of arranging k successes among n observations is given by the <strong>binomial coefficient</strong> <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-332-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1468.035547225203 8210 2470.13864411928" style="width: 19.073ex; height: 5.695ex; vertical-align: -2.384ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJSZ3-28"></use><g transform="translate(856,0)"><use xlink:href="#MJMATHI-6E" x="0" y="676"></use><use xlink:href="#MJMATHI-6B" x="39" y="-686"></use></g><use xlink:href="#MJSZ3-29" x="1577" y="-1"></use><use xlink:href="#MJMAIN-3D" x="2591" y="0"></use><g transform="translate(3767,0)"><rect stroke="none" width="4322" height="60" x="0" y="220"></rect><g transform="translate(1721,676)"><use xlink:href="#MJMATHI-6E"></use><use xlink:href="#MJMAIN-21" x="600" y="0"></use></g><g transform="translate(60,-734)"><use xlink:href="#MJMATHI-6B"></use><use xlink:href="#MJMAIN-21" x="521" y="0"></use><use xlink:href="#MJMAIN-28" x="800" y="0"></use><use xlink:href="#MJMATHI-6E" x="1189" y="0"></use><use xlink:href="#MJMAIN-2212" x="2012" y="0"></use><use xlink:href="#MJMATHI-6B" x="3012" y="0"></use><use xlink:href="#MJMAIN-29" x="3534" y="0"></use><use xlink:href="#MJMAIN-21" x="3923" y="0"></use></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-332">\binom{n}{k} = \frac{n!}{k!(n-k)!}</script>for k = 0, 1, 2, ..., n.</li></ul></li>
<li>Binomial Probability <br>
<ul><li>If X has the binomial distribution with n observations and probability p of success on each observation, the possible values of X are 0, 1, 2, . . . , n. If k is any one of these values,<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-333-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1468.035547225203 13308.168179589375 2436.071094450406" style="width: 30.861ex; height: 5.695ex; vertical-align: -2.384ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><use xlink:href="#MJMATHI-58" x="1141" y="0"></use><use xlink:href="#MJMAIN-3D" x="2271" y="0"></use><use xlink:href="#MJMATHI-6B" x="3327" y="0"></use><use xlink:href="#MJMAIN-29" x="3849" y="0"></use><use xlink:href="#MJMAIN-3D" x="4516" y="0"></use><g transform="translate(5572,0)"><use xlink:href="#MJSZ3-28"></use><g transform="translate(856,0)"><use xlink:href="#MJMATHI-6E" x="0" y="676"></use><use xlink:href="#MJMATHI-6B" x="39" y="-686"></use></g><use xlink:href="#MJSZ3-29" x="1577" y="-1"></use></g><g transform="translate(7886,0)"><use xlink:href="#MJMATHI-70"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6B" x="712" y="583"></use></g><use xlink:href="#MJMAIN-28" x="8858" y="0"></use><use xlink:href="#MJMAIN-31" x="9247" y="0"></use><use xlink:href="#MJMAIN-2212" x="9970" y="0"></use><use xlink:href="#MJMATHI-70" x="10971" y="0"></use><g transform="translate(11474,0)"><use xlink:href="#MJMAIN-29"></use><g transform="translate(389,412)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6E"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2212" x="600" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6B" x="1379" y="0"></use></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-333">P(X = k) = \binom{n}{k}p^k(1-p)^{n-k}</script></li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="9xqz" id="124-binomial-mean-and-standard-deviation">12.4 Binomial Mean and Standard Deviation</h4><ul data-anchor-id="2jzh">
<li>If a count X has the binomial distribution with number of observations n and probability of success p, the mean and standard deviation of X are <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-352-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -461.5355472252029 3041.5555555555557 696.0710944504058" style="width: 7.02ex; height: 1.589ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-3BC"></use><use xlink:href="#MJMAIN-3D" x="881" y="0"></use><use xlink:href="#MJMATHI-6E" x="1937" y="0"></use><use xlink:href="#MJMATHI-70" x="2538" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-352">\mu = np</script> <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-353-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1204.7162972252029 7017 1897.0710944504058" style="width: 16.291ex; height: 4.371ex; vertical-align: -1.722ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-3C3"></use><use xlink:href="#MJMAIN-3D" x="850" y="0"></use><g transform="translate(1906,0)"><use xlink:href="#MJSZ2-221A" x="0" y="-24"></use><rect stroke="none" width="4109" height="60" x="1000" y="1067"></rect><g transform="translate(1000,0)"><use xlink:href="#MJMATHI-6E"></use><use xlink:href="#MJMATHI-70" x="600" y="0"></use><use xlink:href="#MJMAIN-28" x="1104" y="0"></use><use xlink:href="#MJMAIN-31" x="1493" y="0"></use><use xlink:href="#MJMAIN-2212" x="2216" y="0"></use><use xlink:href="#MJMATHI-70" x="3216" y="0"></use><use xlink:href="#MJMAIN-29" x="3720" y="0"></use></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-353">\sigma = \sqrt{np(1-p)}</script></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="brl1" id="125-the-normal-approximation-to-binomial-distributions">12.5 The Normal Approximation to Binomial Distributions</h4><ul data-anchor-id="10l0">
<li>As the number of observations n gets larger, the binomial distribution gets close to a Normal distribution.</li>
<li>Normal Approximation for Binomial Distributions <br>
<ul><li>Suppose that a count X has the binomial distribution with n observations and success probability p. When n is large, the distribution of X is approximately Normal, N(np,<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-379-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -953.5903951652987 5499.944444444444 1302.1807903305973" style="width: 12.717ex; height: 3.006ex; vertical-align: -0.925ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJSZ1-221A" x="0" y="22"></use><rect stroke="none" width="4109" height="60" x="1000" y="813"></rect><g transform="translate(1000,0)"><use xlink:href="#MJMATHI-6E"></use><use xlink:href="#MJMATHI-70" x="600" y="0"></use><use xlink:href="#MJMAIN-28" x="1104" y="0"></use><use xlink:href="#MJMAIN-31" x="1493" y="0"></use><use xlink:href="#MJMAIN-2212" x="2216" y="0"></use><use xlink:href="#MJMATHI-70" x="3216" y="0"></use><use xlink:href="#MJMAIN-29" x="3720" y="0"></use></g><use xlink:href="#MJMAIN-29" x="5110" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-379"> \sqrt{np(1-p)})</script>;</li>
<li>As a rule of thumb, we will use the Normal approximation when n is so large that np <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-380-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -657.0903951652987 778.5 816.1807903305973" style="width: 1.85ex; height: 1.85ex; vertical-align: -0.462ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMAIN-2265"></use></g></svg></span><script type="math/tex" id="MathJax-Element-380">\geq</script> 10 and n(1-p)<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-381-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -657.0903951652987 778.5 816.1807903305973" style="width: 1.85ex; height: 1.85ex; vertical-align: -0.462ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMAIN-2265"></use></g></svg></span><script type="math/tex" id="MathJax-Element-381">\geq</script> 10;</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="ly6w" id="126-the-poisson-distributions">12.6 The Poisson Distributions</h4><ul data-anchor-id="eipe">
<li>Poisson Distribution <br>
<ul><li>A Poisson distribution describes the count X of occurences of a defined event in fixed, finite intervals of time or space when <br>
<ul><li>occurences are all <strong>independent</strong>, and</li>
<li>the probability of an occurence is the same over all possible intervals of the same size.</li></ul></li></ul></li>
<li>Poisson Probability <br>
<ul><li>If X has the Poisson distribution with mean number of occurences per interval <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-431-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -463.0903951652987 603.5 700.1807903305973" style="width: 1.387ex; height: 1.618ex; vertical-align: -0.694ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-3BC"></use></g></svg></span><script type="math/tex" id="MathJax-Element-431">\mu</script>, the possible values of X are 0, 1, 2, ... If k is any one of these values, <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-432-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1550.9296080899492 8495.66855888292 2268.9710032552475" style="width: 19.769ex; height: 5.318ex; vertical-align: -1.734ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMAIN-28" x="751" y="0"></use><use xlink:href="#MJMATHI-58" x="1141" y="0"></use><use xlink:href="#MJMAIN-3D" x="2271" y="0"></use><use xlink:href="#MJMATHI-6B" x="3327" y="0"></use><use xlink:href="#MJMAIN-29" x="3849" y="0"></use><use xlink:href="#MJMAIN-3D" x="4516" y="0"></use><g transform="translate(5692,0)"><rect stroke="none" width="2683" height="60" x="0" y="220"></rect><g transform="translate(60,676)"><use xlink:href="#MJMATHI-65"></use><g transform="translate(466,362)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2212"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-75" x="778" y="0"></use></g><g transform="translate(1521,0)"><use xlink:href="#MJMATHI-75"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6B" x="809" y="513"></use></g></g><g transform="translate(941,-686)"><use xlink:href="#MJMATHI-6B"></use><use xlink:href="#MJMAIN-21" x="521" y="0"></use></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-432">P(X = k) = \frac{e^{-u}u^k}{k!}</script></li>
<li>The mean and variance of the Poisson distribution are both equal to µ, the <br>
mean number of occurrences per interval.</li>
<li>The distribution’s standard deviation σ is equal to √µ.</li></ul></li>
</ul><hr><div class="md-section-divider"></div><h3 data-anchor-id="ztge" id="13-sampling-distributions">13. Sampling Distributions</h3><div class="md-section-divider"></div><h4 data-anchor-id="n19y" id="131-parameters-and-statistics">13.1 Parameters and Statistics</h4><ul data-anchor-id="j170">
<li>Definitions <br>
<ul><li><strong>Parameters</strong>: A parameter is a number that describes the population. In statistical practice, the value of a parameter is not known, because we cannot examine the entire population.</li>
<li><strong>Statistic</strong> A statistic is a number that can be computed from the sample data without making use of any unknown parameters. In practice, we often use a statistic to estimate an unknown parameter.</li></ul></li>
<li>Population and Sample <br>
<ul><li>Statistics come from samples, and parameters come from populations.</li>
<li>Quantitative Data <br>
<ul><li><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-573-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -460.5355472252029 603.5 695.0710944504058" style="width: 1.457ex; height: 1.589ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-3BC"></use></g></svg></span><script type="math/tex" id="MathJax-Element-573">\mu</script> for the <strong>mean of a population</strong>, a fixed parameter that is unknown when we use a sample for inference.</li>
<li><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-574-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.325ex; height: 1.325ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -594.0760770265274 572.5 626.0710944504058" style="width: 1.325ex; height: 1.457ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-574">\bar{x}</script> for the <strong>mean of the sample</strong>, the average of the observations in the sample, a statistic that would almost certainly take a different value if we chose another sample from the same population.</li></ul></li>
<li>Categorical Data <br>
<ul><li><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-575-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="-38.5 -461.5355472252029 542 674.0710944504058" style="width: 1.325ex; height: 1.589ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-70"></use></g></svg></span><script type="math/tex" id="MathJax-Element-575">p</script> for the <strong>population proportion</strong> of individuals of a given type, a parameter often of unknown value.</li>
<li><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-576-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="-38.5 -712.0760770265274 623.8 924.6116242517303" style="width: 1.457ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-70"></use><use xlink:href="#MJMAIN-5E" x="84" y="-1"></use></g></svg></span><script type="math/tex" id="MathJax-Element-576">\hat{p}</script> for the <strong>sample proportion</strong>, the proportion of individuals of a given type in a sample or an experiment.</li></ul></li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="9jui" id="132-statistical-estimation-and-sampling-distributions">13.2 Statistical Estimation and Sampling Distributions</h4><ul data-anchor-id="oe1z">
<li><strong>Sample Distribution</strong>: The sampling distribution of a statistic is the distribution of values taken by the statistic in all possible samples of the same size from the same population.</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="1qvg" id="133-the-sampling-distribution-of-barx">13.3 The Sampling Distribution of <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-434-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.338ex; height: 1.338ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -580.0341356492337 572.5 636.1356469416921" style="width: 1.338ex; height: 1.441ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-34"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-434">\bar{x}</script></h4><ul data-anchor-id="8k86">
<li>Mean and Standardard Deviation of a Sample Mean <br>
<ul><li>Suppose that <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-745-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.325ex; height: 1.325ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -594.0760770265274 572.5 626.0710944504058" style="width: 1.325ex; height: 1.457ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-745">\bar{x}</script> is the mean of an SRS of size n drawn from a large population <br>
with mean µ and standard deviation σ. Then the sampling distribution of x has mean µ and standard deviation <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-746-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -748.4166203236857 1373.9911242215092 1433.8252314206577" style="width: 3.179ex; height: 3.311ex; vertical-align: -1.722ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(120,0)"><rect stroke="none" width="1133" height="60" x="0" y="220"></rect><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-3C3" x="515" y="601"></use><g transform="translate(60,-467)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-221A" x="0" y="-85"></use><rect stroke="none" width="424" height="42" x="589" y="464"></rect><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6E" x="833" y="0"></use></g></g></g></svg></span><script type="math/tex" id="MathJax-Element-746">\frac{\sigma}{\sqrt{n}}</script>. <br>
<ul><li>These facts about the mean and the standard deviation of the sampling distribution of x are true for any population, provided that the population is much larger than the sample (say, at least 20 times larger).</li></ul></li>
<li>The mean of the statistic x is always equal to the mean µ of the population. Because the mean of x is equal to µ, we say that the statistic x is an unbiased estimator of the parameter µ. <br>
<ul><li>An unbiased estimator is “correct on the average” over many samples.</li>
<li>averages are less variable than individual observations.</li></ul></li></ul></li>
<li>Sampling Distribution of a Sample Mean for A Normal Population <br>
<ul><li>The shape of the distribution of <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-747-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.325ex; height: 1.325ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -594.0760770265274 572.5 626.0710944504058" style="width: 1.325ex; height: 1.457ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-747">\bar{x}</script> depends on the shape of the population.</li>
<li>If individual observations have the N(µ, σ) distribution, then the sample <br>
mean <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-748-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.325ex; height: 1.325ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -594.0760770265274 572.5 626.0710944504058" style="width: 1.325ex; height: 1.457ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-748">\bar{x}</script> of an SRS of size n has the N(µ, <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-749-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -748.4166203236857 992.86056916196 1391.398824549465" style="width: 2.252ex; height: 3.179ex; vertical-align: -1.589ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(120,0)"><rect stroke="none" width="752" height="60" x="0" y="220"></rect><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-3C3" x="246" y="601"></use><g fill="red" stroke="red" transform="translate(60,-448)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-5C"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-73" x="500" y="0"></use></g></g></g></svg></span><script type="math/tex" id="MathJax-Element-749">\frac{\sigma}{\s}</script>) distribution.</li>
<li>The results of large random samples are less variable than the results of small samples. <br>
<ul><li>However, the standard deviation of the sampling distribution gets smaller only at the rate √n. To cut the standard deviation of x by 10, we must take 100 times as many observations, not just 10 times as many, and large sample sizes are not always an option.</li></ul></li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="kkw1" id="134-the-central-limit-theorem">13.4 The Central Limit Theorem</h4><ul data-anchor-id="jvot">
<li>Theorem <br>
<ul><li>Draw an SRS of size n from any population with mean µ and finite standard deviation σ. When n is large, the sampling distribution of the sample mean <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-831-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.325ex; height: 1.325ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -594.0760770265274 572.5 626.0710944504058" style="width: 1.325ex; height: 1.457ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-831">\bar{x}</script> is approximately Normal:<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true"><span class="MathJax_SVG" id="MathJax-Element-832-Frame" style="font-size: 100%; display: inline-block;"><span class="noError" style="display: inline-block;">\bar{x}\text{is&nbsp;approximately}&nbsp;N{\mu,\frac{\sigma}{\sqrt{n}}</span></span></div><script type="math/tex; mode=display" id="MathJax-Element-832">\bar{x}\text{is approximately} N{\mu,\frac{\sigma}{\sqrt{n}}</script></li>
<li>More general versions of the central limit theorem say that the distribution of any sum or average of many small random quantities is close to Normal.</li></ul></li>
<li>Application <br>
<ul><li>The central limit theorem allows us to use Normal probability calculations to answer questions about sample means from many observations (questions relying on the sampling distribution of the sample mean) even when the population distribution is not Normal.</li>
<li>The central limit theorem applies to sampling distributions, not to the distribution (histogram) of the data from one random sample of n observations. </li></ul></li>
<li>Thinking <br>
<ul><li>Means of random samples are <strong>less variable</strong> than individual observations.</li>
<li>Means of random samples are <strong>more Normal</strong> than individual observations.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="hjax" id="135-the-sampling-distribution-of-hatp">13.5 The Sampling Distribution of <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-436-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="-38.5 -698.0341356492337 623.8 915.6019591200798" style="width: 1.441ex; height: 2.161ex; vertical-align: -0.617ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-70"></use><use xlink:href="#MJMAIN-5E" x="84" y="-20"></use></g></svg></span><script type="math/tex" id="MathJax-Element-436">\hat{p}</script></h4><ul data-anchor-id="vwg5">
<li>Sample Proportion <br>
<ul><li><strong>Count</strong>: X is a count of the occurences of some categorical outcome in a fixed number of observations.</li>
<li>If the number of observations is n, then the <strong>sample proportion</strong> is <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-974-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="-38.5 -1401.103096894077 16876.411111111112 2302.206193788154" style="width: 39.205ex; height: 5.298ex; vertical-align: -2.119ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-70"></use><use xlink:href="#MJMAIN-5E" x="84" y="-1"></use><use xlink:href="#MJMAIN-3D" x="863" y="0"></use><g transform="translate(2039,0)"><rect stroke="none" width="12132" height="60" x="0" y="220"></rect><g transform="translate(60,677)"><use xlink:href="#MJMAIN-63"></use><use xlink:href="#MJMAIN-6F" x="444" y="0"></use><use xlink:href="#MJMAIN-75" x="945" y="0"></use><use xlink:href="#MJMAIN-6E" x="1501" y="0"></use><use xlink:href="#MJMAIN-74" x="2058" y="0"></use><use xlink:href="#MJMAIN-20" x="2447" y="0"></use><use xlink:href="#MJMAIN-6F" x="2698" y="0"></use><use xlink:href="#MJMAIN-66" x="3198" y="0"></use><use xlink:href="#MJMAIN-20" x="3505" y="0"></use><use xlink:href="#MJMAIN-73" x="3755" y="0"></use><use xlink:href="#MJMAIN-75" x="4150" y="0"></use><use xlink:href="#MJMAIN-63" x="4706" y="0"></use><use xlink:href="#MJMAIN-63" x="5151" y="0"></use><use xlink:href="#MJMAIN-65" x="5595" y="0"></use><use xlink:href="#MJMAIN-73" x="6040" y="0"></use><use xlink:href="#MJMAIN-73" x="6434" y="0"></use><use xlink:href="#MJMAIN-65" x="6829" y="0"></use><use xlink:href="#MJMAIN-73" x="7273" y="0"></use><use xlink:href="#MJMAIN-20" x="7668" y="0"></use><use xlink:href="#MJMAIN-69" x="7918" y="0"></use><use xlink:href="#MJMAIN-6E" x="8197" y="0"></use><use xlink:href="#MJMAIN-20" x="8753" y="0"></use><use xlink:href="#MJMAIN-73" x="9004" y="0"></use><use xlink:href="#MJMAIN-61" x="9398" y="0"></use><use xlink:href="#MJMAIN-6D" x="9899" y="0"></use><use xlink:href="#MJMAIN-70" x="10732" y="0"></use><use xlink:href="#MJMAIN-6C" x="11289" y="0"></use><use xlink:href="#MJMAIN-65" x="11567" y="0"></use></g><g transform="translate(3127,-689)"><use xlink:href="#MJMAIN-73"></use><use xlink:href="#MJMAIN-69" x="394" y="0"></use><use xlink:href="#MJMAIN-7A" x="673" y="0"></use><use xlink:href="#MJMAIN-65" x="1117" y="0"></use><use xlink:href="#MJMAIN-20" x="1562" y="0"></use><use xlink:href="#MJMAIN-6F" x="1812" y="0"></use><use xlink:href="#MJMAIN-66" x="2313" y="0"></use><use xlink:href="#MJMAIN-20" x="2619" y="0"></use><use xlink:href="#MJMAIN-73" x="2870" y="0"></use><use xlink:href="#MJMAIN-61" x="3264" y="0"></use><use xlink:href="#MJMAIN-6D" x="3765" y="0"></use><use xlink:href="#MJMAIN-70" x="4598" y="0"></use><use xlink:href="#MJMAIN-6C" x="5155" y="0"></use><use xlink:href="#MJMAIN-65" x="5433" y="0"></use></g></g><use xlink:href="#MJMAIN-3D" x="14569" y="0"></use><g transform="translate(15745,0)"><rect stroke="none" width="972" height="60" x="0" y="220"></rect><use xlink:href="#MJMATHI-58" x="60" y="676"></use><use xlink:href="#MJMATHI-6E" x="186" y="-686"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-974">\hat{p} = \frac{\text{count of successes in sample}}{\text{size of sample}} = \frac{X}{n}</script></li></ul></li>
<li>Sampling Distribution of a Sample Proportion <br>
<ul><li>Choose an SRS of size n from a large population that contains population proportion p of successes. Let <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-975-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="-38.5 -712.0760770265274 623.8 924.6116242517303" style="width: 1.457ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-70"></use><use xlink:href="#MJMAIN-5E" x="84" y="-1"></use></g></svg></span><script type="math/tex" id="MathJax-Element-975">\hat{p}</script> be the sample proportion of successes,<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-976-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="-38.5 -1401.103096894077 15970.855555555556 2116.58964411928" style="width: 37.086ex; height: 4.901ex; vertical-align: -1.722ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-70"></use><use xlink:href="#MJMAIN-5E" x="84" y="-1"></use><use xlink:href="#MJMAIN-3D" x="863" y="0"></use><g transform="translate(2039,0)"><rect stroke="none" width="13773" height="60" x="0" y="220"></rect><g transform="translate(60,677)"><use xlink:href="#MJMAIN-63"></use><use xlink:href="#MJMAIN-6F" x="444" y="0"></use><use xlink:href="#MJMAIN-75" x="945" y="0"></use><use xlink:href="#MJMAIN-6E" x="1501" y="0"></use><use xlink:href="#MJMAIN-74" x="2058" y="0"></use><use xlink:href="#MJMAIN-20" x="2447" y="0"></use><use xlink:href="#MJMAIN-6F" x="2698" y="0"></use><use xlink:href="#MJMAIN-66" x="3198" y="0"></use><use xlink:href="#MJMAIN-20" x="3505" y="0"></use><use xlink:href="#MJMAIN-73" x="3755" y="0"></use><use xlink:href="#MJMAIN-75" x="4150" y="0"></use><use xlink:href="#MJMAIN-63" x="4706" y="0"></use><use xlink:href="#MJMAIN-63" x="5151" y="0"></use><use xlink:href="#MJMAIN-65" x="5595" y="0"></use><use xlink:href="#MJMAIN-73" x="6040" y="0"></use><use xlink:href="#MJMAIN-73" x="6434" y="0"></use><use xlink:href="#MJMAIN-65" x="6829" y="0"></use><use xlink:href="#MJMAIN-73" x="7273" y="0"></use><use xlink:href="#MJMAIN-20" x="7668" y="0"></use><use xlink:href="#MJMAIN-69" x="7918" y="0"></use><use xlink:href="#MJMAIN-6E" x="8197" y="0"></use><use xlink:href="#MJMAIN-20" x="8753" y="0"></use><use xlink:href="#MJMAIN-74" x="9004" y="0"></use><use xlink:href="#MJMAIN-68" x="9393" y="0"></use><use xlink:href="#MJMAIN-65" x="9950" y="0"></use><use xlink:href="#MJMAIN-20" x="10394" y="0"></use><use xlink:href="#MJMAIN-73" x="10645" y="0"></use><use xlink:href="#MJMAIN-61" x="11039" y="0"></use><use xlink:href="#MJMAIN-6D" x="11540" y="0"></use><use xlink:href="#MJMAIN-70" x="12373" y="0"></use><use xlink:href="#MJMAIN-6C" x="12930" y="0"></use><use xlink:href="#MJMAIN-65" x="13208" y="0"></use></g><use xlink:href="#MJMATHI-6E" x="6586" y="-686"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-976">\hat{p} = \frac{\text{count of successes in the sample}}{n}</script></li>
<li>The <strong>mean</strong> of the sample distribution is p.</li>
<li>The standard deviation of the sampling distribution is <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-977-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -945.7652823245406 5610.944444444444 1297.0710944504058" style="width: 12.98ex; height: 3.046ex; vertical-align: -0.927ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJSZ1-221A" x="0" y="17"></use><rect stroke="none" width="4610" height="60" x="1000" y="808"></rect><g transform="translate(1000,0)"><use xlink:href="#MJMATHI-70"></use><use xlink:href="#MJMAIN-28" x="503" y="0"></use><use xlink:href="#MJMAIN-31" x="893" y="0"></use><use xlink:href="#MJMAIN-2212" x="1615" y="0"></use><use xlink:href="#MJMATHI-70" x="2616" y="0"></use><use xlink:href="#MJMAIN-29" x="3119" y="0"></use><use xlink:href="#MJMAIN-2F" x="3509" y="0"></use><use xlink:href="#MJMATHI-6E" x="4009" y="0"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-977">\sqrt{p(1-p)/n}</script></li>
<li>As the sample size increases, the sampling distribution of <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-978-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="-38.5 -712.0760770265274 623.8 924.6116242517303" style="width: 1.457ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-70"></use><use xlink:href="#MJMAIN-5E" x="84" y="-1"></use></g></svg></span><script type="math/tex" id="MathJax-Element-978">\hat{p}</script> becomes <strong>approximately Normal</strong>.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="k42f" id="136-the-law-of-large-numbers">13.6 The Law of Large Numbers</h4><ul data-anchor-id="fzs7">
<li>if we keep on taking larger and larger samples, the statistic <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-991-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.325ex; height: 1.325ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -594.0760770265274 572.5 626.0710944504058" style="width: 1.325ex; height: 1.457ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-991">\bar{x}</script> isguaranteed to get closer and closer to the parameter µ and the statistic <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-992-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="-38.5 -712.0760770265274 623.8 924.6116242517303" style="width: 1.457ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-70"></use><use xlink:href="#MJMAIN-5E" x="84" y="-1"></use></g></svg></span><script type="math/tex" id="MathJax-Element-992">\hat{p}</script> is guaranteed to get closer and closer to the parameter p. This remarkable fact is called the <strong>law of large numbers</strong>.</li>
</ul><hr><div class="md-section-divider"></div><h3 data-anchor-id="ri8t" id="14-introduction-to-inference">14. Introduction to Inference</h3><div class="md-section-divider"></div><h4 data-anchor-id="pqek" id="141-the-reasoning-of-statistical-estimation">14.1 The Reasoning of Statistical Estimation</h4><ul data-anchor-id="9fxu">
<li>Simple Conditions for Inference About a Mean <br>
<ul><li>We have an SRS from the population of interest. There is no nonresponse or other practical difficulty.</li>
<li>The variable we measure has a perfectly Normal distribution N(µ, σ) in the population.</li>
<li>We don’t know the population mean µ. But we do know the population standard deviation σ.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="w0zl" id="142-margin-of-error-and-confidence-level">14.2 Margin of Error and Confidence Level</h4><ul data-anchor-id="x1fe">
<li>Confidence Interval <br>
<ul><li>A level C confidence interval for a parameter has two parts: <br>
<ul><li>An interval calculated from the data, usually of the form <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1031-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -723.5355472252029 11594.444444444445 948.0710944504058" style="width: 26.887ex; height: 2.252ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-65"></use><use xlink:href="#MJMATHI-73" x="466" y="0"></use><use xlink:href="#MJMATHI-74" x="936" y="0"></use><use xlink:href="#MJMATHI-69" x="1297" y="0"></use><use xlink:href="#MJMATHI-6D" x="1643" y="0"></use><use xlink:href="#MJMATHI-61" x="2521" y="0"></use><use xlink:href="#MJMATHI-74" x="3051" y="0"></use><use xlink:href="#MJMATHI-65" x="3412" y="0"></use><use xlink:href="#MJMAIN-B1" x="4101" y="0"></use><g transform="translate(5101,0)"><use xlink:href="#MJMAIN-6D"></use><use xlink:href="#MJMAIN-61" x="833" y="0"></use><use xlink:href="#MJMAIN-72" x="1334" y="0"></use><use xlink:href="#MJMAIN-67" x="1726" y="0"></use><use xlink:href="#MJMAIN-69" x="2227" y="0"></use><use xlink:href="#MJMAIN-6E" x="2505" y="0"></use><use xlink:href="#MJMAIN-20" x="3062" y="0"></use><use xlink:href="#MJMAIN-6F" x="3312" y="0"></use><use xlink:href="#MJMAIN-66" x="3813" y="0"></use><use xlink:href="#MJMAIN-20" x="4119" y="0"></use><use xlink:href="#MJMAIN-65" x="4370" y="0"></use><use xlink:href="#MJMAIN-72" x="4814" y="0"></use><use xlink:href="#MJMAIN-72" x="5207" y="0"></use><use xlink:href="#MJMAIN-6F" x="5599" y="0"></use><use xlink:href="#MJMAIN-72" x="6100" y="0"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-1031">estimate \pm \text{margin of error}</script>  where the estimate is a sample statistic and the margin of error represents the accuracy of our guess for the parameter.</li>
<li>A confidence level C, which gives the probability that the interval will capture the true parameter value in repeated samples. That is, the confidence level is the success rate for the method</li></ul></li></ul></li>
<li>Interpreting A Confidence Interval <br>
<ul><li>The confidence level is the success rate of the method that produces the interval. We don’t know whether the 95% confidence interval from a particular sample is one of the 95% that capture µ or one of the unlucky 5% that miss.</li>
<li>To say that we are 95% confident that the unknown value of µ lies between 131.1 and 133.9 cm is shorthand for “We got these numbers using a method that gives correct results 95% of the time.”</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="2lpr" id="143-confidence-intervals-for-the-mean-mu">14.3 Confidence Intervals for the Mean <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1032-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -460.5355472252029 603.5 695.0710944504058" style="width: 1.457ex; height: 1.589ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-3BC"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1032">\mu</script></h4><ul data-anchor-id="3l6d">
<li><strong>Critical Value</strong>: In hypothesis testing, a critical value is a point on the test distribution that is compared to the test statistic to determine whether to reject the null hypothesis. If the absolute value of your test statistic is greater than the critical value, you can declare statistical significance and reject the null hypothesis.</li>
<li><strong>Confidence Interval for the Mean of a Normal Population</strong> <br>
<ul><li>Draw an SRS of size n from a Normal population having unknown mean µ and known standard deviation σ. </li>
<li>A level C confidence interval for µ is <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1206-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1128.5983951652986 4679.468055094978 2175.1263625849324" style="width: 10.867ex; height: 5.087ex; vertical-align: -2.543ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-26"></use><use xlink:href="#MJMAIN-B1" x="794" y="0"></use><g transform="translate(1795,0)"><use xlink:href="#MJMATHI-7A"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2217" x="663" y="583"></use></g><g transform="translate(3005,0)"><rect stroke="none" width="1554" height="60" x="0" y="220"></rect><use xlink:href="#MJMATHI-3C3" x="490" y="676"></use><g transform="translate(60,-764)"><use xlink:href="#MJMAIN-221A" x="0" y="-62"></use><rect stroke="none" width="600" height="60" x="833" y="679"></rect><use xlink:href="#MJMATHI-6E" x="833" y="0"></use></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-1206">\bar{x} \pm z^* \frac{\sigma}{\sqrt{n}}</script></li></ul></li>
<li>Four Step Process for Finding the Confidence Interval <br>
<ul><li>State: What is the practical question that requires estimating a parameter?</li>
<li>Plan: Identify the parameter and choose a level of confidence</li>
<li>Solve:Carry out the work in two phases: <br>
<ul><li>Check the conditions for the interval you plan to use</li>
<li>Calculate the confidence interval or use technology to obtain it.</li></ul></li>
<li>Conclude:Return to the practical question to describe your results in this setting</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="vwmy" id="144-the-reasoning-of-tests-of-significance">14.4 The Reasoning of Tests of Significance</h4><ul data-anchor-id="fq8i">
<li>an outcome that would rarely happen if a claim was true is good evidence that the claim is not true. </li>
<li>The significance level for a given hypothesis test is a value for which a P-value less than or equal to is considered statistically significant.  <br>
<ul><li>Typical values for are 0.1, 0.05, and 0.01, and these values are called <strong>significance level</strong></li>
<li>These values correspond to the probability of observing such an extreme value by chance.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="8q2e" id="145-stating-hypotheses">14.5 Stating Hypotheses</h4><ul data-anchor-id="3786">
<li><strong>Null Hypothesis</strong>: The claim tested by a statistical test is called the null hypothesis. The test is designed to assess the strength of the evidence against the null hypothesis. Usually the null hypothesis is a statement of “no effect” or “no difference.”</li>
<li><strong>Alternative Hypothesis</strong>: The claim about the population that we are trying to find evidence for is the <strong>alternative hypothesis</strong>.  <br>
<ul><li>The alternative hypothesis is <strong>one-sided</strong> if it states that a parameter is larger than or that it is smaller than the null hypothesis value.</li>
<li>It is <strong>two-sided</strong> if it states that the parameter is different from the null value.</li></ul></li>
<li>We abbreviate the null hypothesis <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1091-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1091">H_0</script> and the alternative hypothesis <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1092-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1305.913040638277 876.8492690434578" style="width: 3.046ex; height: 1.987ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-61" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1092">H_a</script> .  <br>
<ul><li>Hypotheses always refer to a population, not to a particular outcome.</li></ul></li>
<li>The hypotheses should express the hopes or suspicions we have before we see the data. It is cheating to first look at the data and then frame hypotheses to fit what the data show.</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="jrqj" id="146-p-value-and-statistical-significance">14.6 P-Value and Statistical Significance</h4><ul data-anchor-id="ha0j">
<li>A test statistic calculated from the sample data measures how far the data diverge from the null hypothesis H0. Large values of the statistic show that the data are far from what we would expect if H0 was true.</li>
<li>The probability, computed assuming that H0 is true, that the test statistic would take a value at least as extreme (in the direction of <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1198-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1305.913040638277 876.8492690434578" style="width: 3.046ex; height: 1.987ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-61" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1198">H_a</script> ) as that actually observed is called the P-value of the test. The smaller the P-value, the stronger the evidence against <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1199-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1199">H_0</script> provided by the data.</li>
<li>Failing to find evidence against <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1200-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1200">H_0</script> means only that the data are consistent with H0, not that we have clear evidence that <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1201-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1201">H_0</script> is true.</li>
<li><strong>Statistical Significance</strong> If the P-value is as small as or smaller than α(the significance level), we say that the data are <strong>statistically significant at level α</strong>. <br>
<ul><li>“Significant” in the statistical sense does not mean “important.” It means simply “not likely to happen just by chance because of random variations from sample to sample".</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="pgw3" id="147-test-for-a-population-mean">14.7 Test for a Population Mean</h4><ul data-anchor-id="ueep">
<li>Draw an SRS of size n from a Normal population that has unknown mean µ and known standard deviation σ. To <strong>test the null hypothesis that µ has a specified value</strong> <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1280-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 5114.424999078845 936.0710944504058" style="width: 11.921ex; height: 2.119ex; vertical-align: -0.662ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use><use xlink:href="#MJMAIN-3A" x="1563" y="0"></use><use xlink:href="#MJMATHI-3BC" x="2119" y="0"></use><use xlink:href="#MJMAIN-3D" x="3000" y="0"></use><g transform="translate(4057,0)"><use xlink:href="#MJMATHI-3BC"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="853" y="-213"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-1280">H_0: \mu = \mu_0</script> calculate the <strong>one-sample z test statistic</strong><span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1281-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1293.6436266954015 6800.555555555556 2355.7467235894787" style="width: 15.762ex; height: 5.43ex; vertical-align: -2.517ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-7A"></use><use xlink:href="#MJMAIN-3D" x="746" y="0"></use><g transform="translate(1922,0)"><rect stroke="none" width="4758" height="60" x="0" y="220"></rect><g transform="translate(952,699)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use><use xlink:href="#MJMAIN-2212" x="794" y="0"></use><g transform="translate(1795,0)"><use xlink:href="#MJMATHI-3BC"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="853" y="-213"></use></g></g><g transform="translate(60,-777)"><use xlink:href="#MJMATHI-73"></use><use xlink:href="#MJMATHI-69" x="469" y="0"></use><use xlink:href="#MJMATHI-67" x="815" y="0"></use><use xlink:href="#MJMATHI-6D" x="1295" y="0"></use><use xlink:href="#MJMATHI-61" x="2174" y="0"></use><use xlink:href="#MJMAIN-2F" x="2703" y="0"></use><g transform="translate(3204,0)"><use xlink:href="#MJMAIN-221A" x="0" y="-67"></use><rect stroke="none" width="600" height="60" x="833" y="674"></rect><use xlink:href="#MJMATHI-6E" x="833" y="0"></use></g></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-1281">z = \frac{\bar{x} - \mu_0}{sigma/\sqrt{n}}</script></li>
<li>Four Step Process for the Test of Significance <br>
<ul><li>State:What is the practical question that requires a statistical test?</li>
<li>Plan:Identify the parameter, state null and alternative hypotheses, and choose the type of test that fits your situation.</li>
<li>Solve: Carry the test in three phases: <br>
<ul><li>Check the conditions for the test you plan to use.</li>
<li>Calculate the test statistic.</li>
<li>Find the P-value using a table of Normal probabilities or technology.</li></ul></li>
<li>Conclude:Return to the practical question to describe your results in this setting.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="6hcj" id="148-tests-from-confidence-interval">14.8 Tests from Confidence Interval</h4><ul data-anchor-id="njtg">
<li><strong>Confidence Intervals and Two-Sided Tests</strong>:A level α two-sided significance test rejects a hypothesis <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1293-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1293">H_0</script>: µ = <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1294-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.8597856357989 910.1231029242643 885.6587888282924" style="width: 2.119ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(57.02701986754966) matrix(1 0 0 -1 0 0)">µ</text><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="645" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1294">µ_0</script> exactly when the value <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1295-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.8597856357989 910.1231029242643 885.6587888282924" style="width: 2.119ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(57.02701986754966) matrix(1 0 0 -1 0 0)">µ</text><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="645" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1295">µ_0</script> falls outside a level 1 − α confidence interval for µ.</li>
</ul><hr><div class="md-section-divider"></div><h3 data-anchor-id="63cc" id="15-inference-in-practice">15. Inference in Practice</h3><div class="md-section-divider"></div><h4 data-anchor-id="nf3x" id="151-conditions-for-inference-in-practice">15.1 Conditions for Inference in Practice</h4><ul data-anchor-id="r3ig">
<li>Where did the data come from? <br>
<ul><li>The most important requirement for any inference procedure is that the data come from a process to which the laws of probability apply.</li>
<li>When you use statistical inference, you are acting as if your data are a probability sample or come from a randomized experiment.</li>
<li>If your data don’t come from a probability sample or a randomized comparative experiment, your conclusions may be challenged.</li>
<li>There is no simple rule for deciding when you can act as if a sample is an SRS. Pay attention to these cautions: <br>
<ul><li>Practical problems such as nonresponse in samples or dropouts from an experiment can hinder inference from even a well-designed study. </li>
<li>Different methods are needed for different designs.</li>
<li>There is no cure for fundamental flaws like voluntary response surveys, uncontrolled experiments, or biased samples.</li></ul></li></ul></li>
<li>What is the shape of the population distribution? <br>
<ul><li>The condition that the population should be Normally distributed is less essential than where the data come from. <br>
<ul><li>This is true because the z procedures and many other procedures designed for Normal distributions are based on Normality of the sample mean <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1329-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.325ex; height: 1.325ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -594.0760770265274 572.5 626.0710944504058" style="width: 1.325ex; height: 1.457ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-1329">\bar{x}</script>, not Normality of individual observations.</li>
<li>The central limit theorem tells us that <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1330-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.325ex; height: 1.325ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -594.0760770265274 572.5 626.0710944504058" style="width: 1.325ex; height: 1.457ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-1330">\bar{x}</script> is more Normal than the individual observations and that <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1331-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span style="display: inline-block; white-space: nowrap; padding: 1px 0px;"><span style="display: inline-block; position: relative; width: 1.325ex; height: 1.325ex; vertical-align: 0ex;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -594.0760770265274 572.5 626.0710944504058" style="width: 1.325ex; height: 1.457ex; position: absolute; bottom: 0ex; left: 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-78"></use><use xlink:href="#MJMAIN-AF" x="63" y="-15"></use></g></svg></span></span></span><script type="math/tex" id="MathJax-Element-1331">\bar{x}</script> becomes more Normal as the size of the sample increases.</li></ul></li>
<li>Outliers can distort the results of inference.  <br>
<ul><li>Any inference procedure based on sample statistics like the sample mean x that are not resistant to outliers can be strongly influenced by a few extreme observations.</li></ul></li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="8t7x" id="152-how-confidence-intervals-behave">15.2 How Confidence Intervals Behave</h4><ul data-anchor-id="1una">
<li>How do we Get a Smaller Margin of Error <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1416-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span class="noError" style="display: inline-block;">=&nbsp;z^*&nbsp;\frac{\sigma}{\frac{n}}</span></span><script type="math/tex" id="MathJax-Element-1416"> = z^* \frac{\sigma}{\frac{n}}</script> <br>
<ul><li><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1417-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -709.939307258134 923.356943983867 739.4748544833369" style="width: 2.119ex; height: 1.722ex; vertical-align: -0.132ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-7A"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2217" x="663" y="513"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1417">z^*</script> gets smaller. <br>
<ul><li>There is a trade-off between the confidence level and the margin of error. To obtain a smaller margin of error from the same data, you must be willing to accept lower confidence.</li></ul></li>
<li><span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1418-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -449.5355472252029 572.5 479.0710944504058" style="width: 1.325ex; height: 1.06ex; vertical-align: -0.132ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-3C3"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1418">\sigma</script> is smaller. </li>
<li>n gets larger. <br>
<ul><li>because n appears under a square root sign, we must take four times as many <br>
observations in order to cut the margin of error in half.</li></ul></li></ul></li>
<li>The Margin of Error Accounts only for Sampling Error <br>
<ul><li>The margin of error in a confidence interval covers only random sampling errors.</li>
<li>Practical difficulties such as undercoverage and nonresponse are often more serious than random sampling error. The margin of error does not take such difficulties into account.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="ayla" id="153-how-significance-tests-behave">15.3 How Significance Tests Behave</h4><ul data-anchor-id="xh0m">
<li>how small a P-value is convincing evidence against the null hypothesis? <br>
<ul><li>How plausible is <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1581-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1581">H_0</script> <br>
<ul><li>? If <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1582-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1582">H_0</script> represents an assumption that the people you must convince have believed for years, strong evidence (small P) will be needed to persuade them.</li></ul></li>
<li>What are the consequences of rejecting <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1583-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1583">H_0</script>?</li>
<li>there is no sharp border between “significant” and “insignificant,” only increasingly strong evidence as the P -value decreases.</li></ul></li>
<li>Significance depends on the alternative hypothesis <br>
<ul><li>the P-value for a one-sided test is one-half the P-value for the two-sided test of the same null hypothesis based on the same data. </li>
<li>It makes sense that the evidence against H0 is stronger when the alternative is one-sided, because the evidence is based on the data plus information about the direction of possible deviations from <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1584-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1584">H_0</script>.</li></ul></li>
<li>Significance Depends on Sample Size <br>
<ul><li>How important an effect is depends on the size of the effect as well as on its statistical significance.</li>
<li>Because large random samples have small chance variation, very small population effects can be highly significant if the sample is large.</li>
<li>Because small random samples have a lot of chance variation, even large population effects can fail to be statistically significant if the sample is small.</li>
<li>Statistical significance does not tell us whether an effect is large enough to be important. That is, statistical significance is not the same thing as practical significance.</li></ul></li>
<li>Beware of multiple analyses <br>
<ul><li>Running one test and reaching the 5% level of significance is reasonably good evidence that you have found something. Running 20 tests and reaching that level only once is not.</li></ul></li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="x3x0" id="154-sample-size-for-confidence-intervals">15.4 Sample Size for Confidence Intervals</h4><ul data-anchor-id="77j6">
<li>The confidence interval for the mean of a Normal population will have a specified margin of error m when the sample size is <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1604-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1666.6561852062546 6050.652776856623 2634.6917324314577" style="width: 14.04ex; height: 6.093ex; vertical-align: -2.384ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-6E"></use><use xlink:href="#MJMAIN-3D" x="878" y="0"></use><use xlink:href="#MJSZ3-28" x="1934" y="-1"></use><g transform="translate(2957,0)"><rect stroke="none" width="1615" height="60" x="0" y="220"></rect><g transform="translate(60,676)"><use xlink:href="#MJMATHI-7A"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2217" x="663" y="513"></use><use xlink:href="#MJMATHI-3C3" x="923" y="0"></use></g><use xlink:href="#MJMATHI-6D" x="368" y="-686"></use></g><g transform="translate(4860,0)"><use xlink:href="#MJSZ3-29"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-32" x="1041" y="1665"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-1604">n = \bigg(\frac{z^*\sigma}{m}\bigg)^2</script></li>
<li>Notice that it is the size of the sample that determines the margin of error. The size of the population does not influence the sample size we need. (This is true as long as the population is much larger than the sample.)</li>
</ul><div class="md-section-divider"></div><h4 data-anchor-id="scgx" id="155-sample-size-for-test-of-significance-the-power-of-statistical-test">15.5 Sample Size for Test of Significance: The Power of Statistical Test</h4><ul data-anchor-id="vw0t">
<li>Here are the questions we must answer to decide how large a sample we must take: <br>
<ul><li>Significance Level <br>
<ul><li>How much protection do we want against getting a statistically significant result from our sample when there really is no effect in the population?</li></ul></li>
<li>Effect Size <br>
<ul><li>How large an effect in the population is important in practice?</li></ul></li>
<li>Power <br>
<ul><li>How confident do we want to be that our study will detect an effect of the size we think is important?</li></ul></li></ul></li>
<li><strong>Power</strong>: The power of a test against a specific alternative is the probability that the test will reject H0 at a chosen significance level α when the specified alternative value of the parameter is true.</li>
<li>Type I and Type II Errors <br>
<ul><li>If we reject <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1684-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1684">H_0</script> when in fact <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1685-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1685">H_0</script> is true, this is a <strong>Type I error</strong>. <br>
<ul><li>The significance level α of any fixed level test is the probability of a Type I error.</li></ul></li>
<li>If we fail to reject <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1686-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1285.406943983867 885.3345504176964" style="width: 3.046ex; height: 2.119ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-30" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1686">H_0</script> when in fact <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1687-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -701.5355472252029 1305.913040638277 876.8492690434578" style="width: 3.046ex; height: 1.987ex; vertical-align: -0.53ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-48"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-61" x="1175" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1687">H_a</script> is true, this is a <strong>Type II error</strong>.  <br>
<ul><li>The probability of a Type II error is called β.</li>
<li>The power of a test against any alternative is 1 minus the probability of a Type II error for that alternative: power = 1 − β.</li></ul></li></ul></li>
</ul><div class="md-section-divider"></div><h3 data-anchor-id="5emy" id="16-from-exploration-to-inference">16. From Exploration to Inference</h3><ul data-anchor-id="duog">
<li>Statistical Inference <br>
<ul><li>Statistical inference draws conclusions about a population on the basis of sample data and uses probability to indicate how reliable the conclusions are. </li>
<li>A confidence interval estimates an unknown parameter. <br>
<ul><li>A confidence level is the success rate of the method for a confidence interval. This is the probability that the method actually produces an interval that contains the unknown parameter.</li></ul></li>
<li>A Significance test shows how strong the evidence is for some claim about a parameter. <br>
<ul><li>A P-value tells us how surprising the observed outcome would be if the null hypothesis was true.</li>
<li>That is, P is the probability that the test would produce a result at least as extreme as the observed result if the null hypothesis really was true. </li></ul></li></ul></li>
<li>Summary <br>
<ul><li>Sampling and Observational Studies</li>
<li>Experiments</li>
<li>Probability</li>
<li>General Rules of Probability</li>
<li>Density Curves and Normal Distributions</li>
<li>Discrete Distributions</li>
<li>Sampling Distributions</li>
<li>The Sampling Distribution of a Sample Mean</li>
<li>The Sampling Distribution of a Sample Proportion</li>
<li>Confidence Intervals</li>
<li>Significance Tests</li></ul></li>
</ul><div class="md-section-divider"></div><h2 data-anchor-id="1uad" id="iii-statistical-inference">III Statistical Inference</h2><div class="md-section-divider"></div><h3 data-anchor-id="042v" id="17-inference-about-a-population-mean">17 Inference about a Population Mean</h3><div class="md-section-divider"></div><h3 data-anchor-id="l131" id="18-comparing-two-means">18. Comparing Two Means</h3><div class="md-section-divider"></div><h3 data-anchor-id="pg9m" id="19-inference-about-a-population-proportion">19. Inference about a Population Proportion</h3><div class="md-section-divider"></div><h3 data-anchor-id="9suk" id="20-comparing-two-proportions">20. comparing Two Proportions</h3><div class="md-section-divider"></div><h3 data-anchor-id="4vb8" id="21-the-chi-square-test-for-goodness-of-fit">21. The Chi-Square Test for Goodness of Fit</h3><div class="md-section-divider"></div><h3 data-anchor-id="or12" id="22-the-chi-square-test-for-two-way-tables">22. The Chi-Square Test for Two-Way Tables</h3></div>
</body>
</html>